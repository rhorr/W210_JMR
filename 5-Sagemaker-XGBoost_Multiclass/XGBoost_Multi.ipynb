{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c96c009-8003-45a7-bbd1-b208394e12ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "### XGBoost_LOS Build and Testing Local - Multiclass only\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb0ad69c-d333-48cf-9414-1c94394f4023",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a48f7911-35db-4eb1-ac06-e5c9042d165f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing key packages\n",
    "import io\n",
    "import os\n",
    "import boto3\n",
    "import sagemaker\n",
    "import time\n",
    "import botocore\n",
    "from sagemaker import get_execution_role, image_uris, model_uris, script_uris, hyperparameters\n",
    "from sagemaker.estimator import Estimator\n",
    "from sagemaker.utils import name_from_base\n",
    "from sagemaker.tuner import HyperparameterTuner\n",
    "from time import gmtime, strftime\n",
    "import matplotlib as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c7fcf48-a3ea-4a9e-af45-3fa29fbf6804",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Setting up\n",
    "\n",
    "role = sagemaker.get_execution_role()\n",
    "boto_session = boto3.Session()\n",
    "region = boto_session.region_name\n",
    "sess = sagemaker.Session(boto_session=boto_session)\n",
    "\n",
    "print(\"Role:\", role)\n",
    "print(\"Region:\", region)\n",
    "print(\"SageMaker Session Region:\", sess.boto_region_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01a73edc-dc84-412c-8689-8b4ddc3816a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Setting up Bucket Links/Info\n",
    "bucket='xgb-los-multi'\n",
    "s3_bucket_prefix= \"xgb-multi-code/\"\n",
    "prefix = f\"{bucket}/{s3_bucket_prefix}\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d74e05e-2f58-4810-a3ca-b225cd3ce144",
   "metadata": {},
   "outputs": [],
   "source": [
    "prefix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cad4a77-c03b-4bbf-9c0f-98d77d452243",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Set XGB Container\n",
    "\n",
    "container = sagemaker.image_uris.retrieve(\"xgboost\", region, \"1.7-1\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b822194-e428-4729-98e7-b4e002c42eb1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fefffc8a-83aa-42a2-afd6-91669f28683c",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Train/Test/Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f6f0ed5-4f02-47ab-8a18-3541cfb1a2b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load Source file to do encoding and split train/test\n",
    "\n",
    "#s3://sagemaker-us-east-2-917456409349/sagemaker/adoption/golden_record/df_cat_dog_harmonized_Sample_With_Outcome.csv\n",
    "\n",
    "bucket = \"sagemaker-us-east-2-917456409349\"\n",
    "key = \"sagemaker/adoption/golden_record/df_cat_dog_harmonized.csv\" \n",
    "\n",
    "# Initialize S3 client\n",
    "s3_client = boto3.client(\"s3\")\n",
    "\n",
    "# Fetch the object from S3\n",
    "obj = s3_client.get_object(Bucket=bucket, Key=key)\n",
    "\n",
    "# Read into pandas DataFrame\n",
    "df = pd.read_csv(io.BytesIO(obj['Body'].read()))\n",
    "\n",
    "# Show the first few rows\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edd5700d-7bc7-4636-a08b-a7f4cb729392",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Deduping\n",
    "\n",
    "# Drop duplicates, keeping the last record for each animal_id\n",
    "df_deduped = df.drop_duplicates(subset='primary_key', keep='last')\n",
    "\n",
    "\n",
    "print(\"Original rows:\", len(df))\n",
    "print(\"After deduplication:\", len(df_deduped))\n",
    "df = df_deduped.copy()\n",
    "print(\"New rows for df:\", len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df0f0b28-5a1d-4d2b-ae27-8295aa479bd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Adding Custom Train/Test/Split\n",
    "def assign_split(row):\n",
    "    if row['outcome_year'] <= 2022:\n",
    "        return \"train\"\n",
    "    elif row['outcome_year'] in [2023, 2024]:\n",
    "        return \"validate\"\n",
    "    elif row['outcome_year'] == 2025:\n",
    "        return \"test\"\n",
    "    else:\n",
    "        return \"exclude\"  # fallback for unexpected years\n",
    "\n",
    "df['split'] = df.apply(assign_split, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b8f23f0-c798-4c3f-9b3d-9ecf2f9cd849",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Naming features to keep and drop if needed, but won't as keeping standard format of xlsx.\n",
    "features_to_keep = ['outcome_type_harmonized_grouped','animal_type', 'primary_breed_harmonized', 'primary_color_harmonized',\n",
    "    'sex', 'intake_type_harmonized',\n",
    "    'Is_returned', 'has_name', 'is_mix', 'Num_returned', 'age_months','stay_length_days', 'min_height', 'max_height',\n",
    "    'min_weight', 'max_weight', 'min_expectancy', 'max_expectancy',\n",
    "    'grooming_frequency_value', 'shedding_value', 'energy_level_value',\n",
    "    'trainability_value', 'demeanor_value'\n",
    "]\n",
    "\n",
    "# # Trim the DataFrame to only those columns\n",
    "# df = df[features_to_keep].copy()\n",
    "\n",
    "# #EDIT: Only training on models with features to keep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dbf3fe3-aead-421f-bb34-51dd6257a0ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "#See all columns\n",
    "all_columns = df.columns.tolist()\n",
    "print(all_columns)\n",
    "print(\"Total columns:\", len(all_columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d53d2e39-66c5-4695-ab0e-b4da16c3cce4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pre-encoding Adoption\n",
    "df['outcome_type_harmonized_grouped'] = (df['outcome_type_harmonized_grouped'] == 'adopted').astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bc4a4ad-22a3-4292-a34e-6cfac466f3a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Encoding\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Copy original DataFrame\n",
    "encoded_df = df.copy()\n",
    "\n",
    "# Specific columns we want to encode\n",
    "columns_to_encode = [\n",
    "    'animal_type', 'primary_breed_harmonized', 'primary_color_harmonized',\n",
    "    'sex', 'intake_type_harmonized',\n",
    "    'Is_returned', 'has_name', 'is_mix'\n",
    "]\n",
    "\n",
    "# Dictionary to store label encoders\n",
    "le_dict = {}\n",
    "\n",
    "# Apply label encoding to specified columns, save in new columns\n",
    "for col in columns_to_encode:\n",
    "    le = LabelEncoder()\n",
    "    encoded_col_name = f\"Encoded-{col}\"\n",
    "    encoded_df[encoded_col_name] = le.fit_transform(encoded_df[col].astype(str))\n",
    "    le_dict[col] = le\n",
    "\n",
    "# Fill missing age_months with median\n",
    "median_age = encoded_df['age_months'].median()\n",
    "encoded_df['age_months'] = encoded_df['age_months'].fillna(median_age)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2e849c5-d7ab-437c-b856-088665e61c70",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.shape(encoded_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e905329e-2f71-4f44-949e-283888858bf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "761c76db-aa3e-43c5-b350-3284a5660e1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving Encoding locally JIC\n",
    "import pickle\n",
    "\n",
    "with open(\"label_encoders.pkl\", \"wb\") as f:\n",
    "    pickle.dump(le_dict, f)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17feb769-d415-483b-a5c0-10f3d269eb1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Because we are doing a multiclass, we need to add a column for multiclass as follows\n",
    "#We use \"Other\" where mapping does not occur and will filter out of our predction below.\n",
    "\n",
    "# Define mapping for non-adopted subtypes\n",
    "non_adopted_subtypes = {\n",
    "    \"rescue\": \"rescue\",\n",
    "    \"foster\": \"foster\",\n",
    "    \"return to owner\": \"return_to_owner\",\n",
    "    \"foster to adopt\": \"foster\",\n",
    "    \"return to rescue\": \"rescue\",\n",
    "    \"rtf\": \"foster\"\n",
    "}\n",
    "\n",
    "# Map outcome types to the target labels, default others to \"other\"\n",
    "encoded_df[\"non_adopted_label\"] = (\n",
    "    encoded_df[\"outcome_type_harmonized\"]\n",
    "    .map(non_adopted_subtypes)\n",
    "    .fillna(\"other\")\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64b60271-adde-481b-81d3-2f1693c38d5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#inspect columns\n",
    "encoded_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fbb00d8-919a-475e-b37b-481b1e34c899",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting for training\n",
    "\n",
    "df_train = encoded_df[encoded_df['split'] == 'train']\n",
    "df_test = encoded_df[encoded_df['split'] == 'test']\n",
    "df_validate = encoded_df[encoded_df['split'] == 'validate']\n",
    "# Save each to CSV (no index)\n",
    "df_train.to_csv(\"train.csv\", index=False)\n",
    "df_test.to_csv(\"test.csv\", index=False)\n",
    "df_validate.to_csv(\"validate.csv\", index=False)\n",
    "\n",
    "# Output sizes\n",
    "print(\"Train rows:\", len(df_train))\n",
    "print(\"Test rows:\", len(df_test))\n",
    "print(\"Validate rows:\", len(df_validate))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eab85514-3b2a-40d7-ad0a-650580271874",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Model Training our XGBoost Multiclass on Non-Adopted so we can Test only on those with proba <0.5. Locally-only need to do once "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ac44460-db9b-4916-a798-6b8b37c68fc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TRain Model so we can get a prediction, if our predictions are similar to endpoitn testing in other files will use this to subset on\n",
    "#adoption prediction, then do XGBoost Grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed4452a1-ac35-4c3e-8b10-c9c536c92fd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Running AMT to see if can improve Test performance\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "feature_columns = [\n",
    "'Encoded-animal_type', \n",
    "    'Encoded-primary_breed_harmonized', \n",
    "    'Encoded-primary_color_harmonized', \n",
    "    'Encoded-sex', \n",
    "    'Encoded-intake_type_harmonized', \n",
    "    'Encoded-Is_returned', \n",
    "    'Encoded-has_name', \n",
    "    'Encoded-is_mix',\n",
    "    'age_months',    \n",
    "    'Num_returned', \n",
    "    'stay_length_days', #We comment this out in our prediction for los but not here\n",
    "    'min_height', \n",
    "    'max_height',\n",
    "    'min_weight', \n",
    "    'max_weight', \n",
    "    'min_expectancy', \n",
    "    'max_expectancy',\n",
    "    'grooming_frequency_value', \n",
    "    'shedding_value', \n",
    "    'energy_level_value',\n",
    "    'trainability_value', \n",
    "    'demeanor_value'\n",
    "]\n",
    "\n",
    "\n",
    "# prepare datasets using only selected features\n",
    "X_train = df_train[feature_columns]\n",
    "y_train = df_train['outcome_type_harmonized_grouped']\n",
    "\n",
    "X_val = df_validate[feature_columns]\n",
    "y_val = df_validate['outcome_type_harmonized_grouped']\n",
    "\n",
    "X_test = df_test[feature_columns]\n",
    "y_test = df_test['outcome_type_harmonized_grouped']\n",
    "\n",
    "# Combine train and val for GridSearchCV\n",
    "X_trainval = pd.concat([X_train, X_val])\n",
    "y_trainval = pd.concat([y_train, y_val])\n",
    "\n",
    "# Define parameter grid\n",
    "param_grid = {\n",
    "    'max_depth': [3, 5, 7],\n",
    "    'learning_rate': [0.05, 0.1, 0.2],\n",
    "    'gamma': [0, 2, 4],\n",
    "    'min_child_weight': [1, 4, 6],\n",
    "    'subsample': [0.6, 0.8, 1.0],\n",
    "    'n_estimators': [50, 100],\n",
    "}\n",
    "\n",
    "# Initialize model\n",
    "xgb_base = XGBClassifier(\n",
    "    objective='binary:logistic',\n",
    "    eval_metric='logloss',\n",
    "    n_jobs=-1,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Grid search with 3-fold CV\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=xgb_base,\n",
    "    param_grid=param_grid,\n",
    "    scoring='f1',\n",
    "    cv=3,\n",
    "    verbose=1,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# Fit grid search\n",
    "grid_search.fit(X_trainval, y_trainval)\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "print(\"Best parameters found:\", grid_search.best_params_)\n",
    "\n",
    "# Evaluation function\n",
    "def evaluate_performance(X, y_true, dataset_name):\n",
    "    y_pred = best_model.predict(X)\n",
    "    print(f\"\\n{dataset_name} Set Performance:\")\n",
    "    print(classification_report(y_true, y_pred))\n",
    "\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "    disp.plot(cmap='Blues')\n",
    "    plt.title(f\"{dataset_name} Confusion Matrix\")\n",
    "    plt.show()\n",
    "\n",
    "# Run evaluations\n",
    "evaluate_performance(X_train, y_train, \"Training\")\n",
    "evaluate_performance(X_val, y_val, \"Validation\")\n",
    "evaluate_performance(X_test, y_test, \"Test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5635c9cc-973f-45b6-a751-7706e7eb33db",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model is consistent so continuing the process "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "406fec35-3d72-4e0b-acc7-447c37060c08",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Outputting Best Parameters, saving model \n",
    "\n",
    "best_params = grid_search.best_params_\n",
    "print(best_params)\n",
    "\n",
    "best_model.save_model(\"best_xgb_model_local.json\") \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aad8250f-54f8-4f99-87f1-a5a820946397",
   "metadata": {},
   "outputs": [],
   "source": [
    "#We get exact same parameters so good to rain on this new data set for our likely outcome for non-adoption\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9002230f-ef91-4046-9dc8-f8e9ec0029f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now we run whole encoded data set through to add our prediction and probability \n",
    "from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Define feature cols\n",
    "feature_columns_los = [\n",
    "    'Encoded-animal_type', \n",
    "    'Encoded-primary_breed_harmonized', \n",
    "    'Encoded-primary_color_harmonized', \n",
    "    'Encoded-sex', \n",
    "    'Encoded-intake_type_harmonized', \n",
    "    'Encoded-Is_returned', \n",
    "    'Encoded-has_name', \n",
    "    'Encoded-is_mix',\n",
    "    'age_months',    \n",
    "    'Num_returned', \n",
    "    'stay_length_days',\n",
    "    'min_height', \n",
    "    'max_height',\n",
    "    'min_weight', \n",
    "    'max_weight', \n",
    "    'min_expectancy', \n",
    "    'max_expectancy',\n",
    "    'grooming_frequency_value', \n",
    "    'shedding_value', \n",
    "    'energy_level_value',\n",
    "    'trainability_value', \n",
    "    'demeanor_value'\n",
    "]\n",
    "\n",
    "# Prepare features from encoded_df\n",
    "X_encoded = encoded_df[feature_columns_los]\n",
    "\n",
    "# Check if ground truth labels exist\n",
    "if 'outcome_type_harmonized_grouped' in encoded_df.columns:\n",
    "    y_encoded = encoded_df['outcome_type_harmonized_grouped']\n",
    "else:\n",
    "    y_encoded = None\n",
    "\n",
    "# Run prediction and predicted probabilities\n",
    "y_pred = best_model.predict(X_encoded)\n",
    "y_proba = best_model.predict_proba(X_encoded)[:, 1]  # Probability of positive class (adopted)\n",
    "\n",
    "# Add predictions and probabilities to df\n",
    "encoded_df['predicted_label'] = y_pred\n",
    "encoded_df['predicted_proba'] = y_proba\n",
    "\n",
    "# Evaluate Performance\n",
    "if y_encoded is not None:\n",
    "    print(\"Classification Report on encoded_df:\")\n",
    "    print(classification_report(y_encoded, y_pred))\n",
    "\n",
    "    cm = confusion_matrix(y_encoded, y_pred)\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "    disp.plot(cmap='Blues')\n",
    "    plt.title(\"Confusion Matrix on encoded_df\")\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"No ground truth labels found; predictions added to DataFrame.\")\n",
    "\n",
    "\n",
    "print(encoded_df[['predicted_label', 'predicted_proba']].head())\n",
    "\n",
    "encoded_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32dbe2b8-b444-4195-b5b2-6a21cd590d39",
   "metadata": {},
   "outputs": [],
   "source": [
    "#See all columns\n",
    "all_columns = encoded_df.columns.tolist()\n",
    "print(all_columns)\n",
    "print(\"Total columns:\", len(all_columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69b926ad-b2ad-4a7d-be17-0c4bd7e9cf01",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.shape(encoded_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ab4377a-c062-4a6b-ae64-8a48b4874365",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Training Multiclass now locally to ensure we get good results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f6780e1-bf28-4ffc-89b6-88cbfceddebc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#First thing we need to do is encode non_adopted_label\n",
    "\n",
    "#Define mapping dictionary\n",
    "label_map = {\n",
    "    'foster': 0,\n",
    "    'rescue': 1,\n",
    "    'return_to_owner': 2,\n",
    "    'other': -1  # We'll filter these out later\n",
    "}\n",
    "\n",
    "#Apply mapping\n",
    "encoded_df[\"Encoded-non_adopted_label\"] = (\n",
    "    encoded_df[\"non_adopted_label\"].map(label_map).astype('Int64')  # Use Int64 to allow -1 for \"other\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5792b228-fa67-4dd2-9c50-ce25a942a86e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we'll train locally to find our best fit but first we split again for train/test/validate\n",
    "# Splitting for training\n",
    "#Dropping any \"Other\" non_adopted cases\n",
    "\n",
    "\n",
    "multi_predicted_df_train = encoded_df[encoded_df['split'] == 'train']\n",
    "multi_predicted_df_test = encoded_df[(encoded_df['split'] == 'test') & (encoded_df['predicted_proba'] < 0.5)]\n",
    "multi_predicted_df_validate = encoded_df[encoded_df['split'] == 'validate']\n",
    "\n",
    "# Filter out rows where non_adopted_label is 'other'\n",
    "valid_classes = ['foster', 'rescue', 'return_to_owner']\n",
    "multi_predicted_df_train = multi_predicted_df_train[multi_predicted_df_train['non_adopted_label'].isin(valid_classes)]\n",
    "multi_predicted_df_test = multi_predicted_df_test[multi_predicted_df_test['non_adopted_label'].isin(valid_classes)]\n",
    "multi_predicted_df_validate = multi_predicted_df_validate[multi_predicted_df_validate['non_adopted_label'].isin(valid_classes)]\n",
    "\n",
    "# Save cleaned splits\n",
    "multi_predicted_df_train.to_csv(\"multi_train.csv\", index=False)\n",
    "multi_predicted_df_test.to_csv(\"multi_test.csv\", index=False)\n",
    "multi_predicted_df_validate.to_csv(\"multi_validate.csv\", index=False)\n",
    "\n",
    "# Output sizes and unique labels for sanity check\n",
    "print(\" Filtered Datasets\")\n",
    "print(\"Train rows:\", len(multi_predicted_df_train), \"Classes:\", multi_predicted_df_train['non_adopted_label'].unique())\n",
    "print(\"Validate rows:\", len(multi_predicted_df_validate), \"Classes:\", multi_predicted_df_validate['non_adopted_label'].unique())\n",
    "print(\"Test rows:\", len(multi_predicted_df_test), \"Classes:\", multi_predicted_df_test['non_adopted_label'].unique())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2306b107-ea2e-4b5f-bfd6-91699a149131",
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_predicted_df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9baae25-0237-48b1-a296-ee9dac93b0ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Then we train locally using AMT to find our best model fit and ensure our Test is only on animals\n",
    "#that are predicted adoption <50%\n",
    "#Trying to predict multiclass \"non_adopt_label\"\n",
    "\n",
    "#Running AMT to see if can improve Test performance\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Features and target\n",
    "feature_columns_multi = [\n",
    "    'Encoded-animal_type', \n",
    "    'Encoded-primary_breed_harmonized', \n",
    "    'Encoded-primary_color_harmonized', \n",
    "    'Encoded-sex', \n",
    "    'Encoded-intake_type_harmonized', \n",
    "    'Encoded-Is_returned', \n",
    "    'Encoded-has_name', \n",
    "    'Encoded-is_mix',\n",
    "    'age_months',    \n",
    "    'Num_returned', \n",
    "    'stay_length_days',\n",
    "    'min_height', \n",
    "    'max_height',\n",
    "    'min_weight', \n",
    "    'max_weight', \n",
    "    'min_expectancy', \n",
    "    'max_expectancy',\n",
    "    'grooming_frequency_value', \n",
    "    'shedding_value', \n",
    "    'energy_level_value',\n",
    "    'trainability_value', \n",
    "    'demeanor_value'\n",
    "]\n",
    "\n",
    "# Filter and ensure no NaN\n",
    "X_trainval = pd.concat([\n",
    "    multi_predicted_df_train[feature_columns_multi],\n",
    "    multi_predicted_df_validate[feature_columns_multi]\n",
    "]).fillna(0)\n",
    "\n",
    "# Use encoded target directly\n",
    "y_trainval = pd.concat([\n",
    "    multi_predicted_df_train['Encoded-non_adopted_label'],\n",
    "    multi_predicted_df_validate['Encoded-non_adopted_label']\n",
    "])\n",
    "\n",
    "X_test = multi_predicted_df_test[feature_columns_multi].fillna(0)\n",
    "y_test = multi_predicted_df_test['Encoded-non_adopted_label']\n",
    "\n",
    "# Parameter grid for AMT\n",
    "param_grid = {\n",
    "    'max_depth': [3, 5, 7],\n",
    "    'learning_rate': [0.05, 0.1, 0.2],\n",
    "    'gamma': [0, 1, 4],\n",
    "    'min_child_weight': [1, 4, 6],\n",
    "    'subsample': [0.6, 0.8, 1.0],\n",
    "    'n_estimators': [50, 100]\n",
    "}\n",
    "\n",
    "# XGB Classifier\n",
    "xgb_model = XGBClassifier(\n",
    "    objective='multi:softprob',\n",
    "    num_class=3,  # foster, rescue, return_to_owner\n",
    "    eval_metric='mlogloss',\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Grid Search with F1 macro\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=xgb_model,\n",
    "    param_grid=param_grid,\n",
    "    scoring='f1_macro',\n",
    "    cv=3,\n",
    "    verbose=1,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# Fit model\n",
    "grid_search.fit(X_trainval, y_trainval)\n",
    "\n",
    "best_model_multi = grid_search.best_estimator_\n",
    "print(\"Best Parameters multi:\", grid_search.best_params_)\n",
    "\n",
    "# Evaluate on test\n",
    "y_pred = best_model_multi.predict(X_test)\n",
    "\n",
    "print(\"\\nClassification Report:\\n\",\n",
    "      classification_report(y_test, y_pred, target_names=['foster', 'rescue', 'return_to_owner']))\n",
    "print(\"\\nConfusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5748de3-f6e8-45e0-946c-780e800d7fe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Outputting Best Parameters, saving model \n",
    "\n",
    "best_params_multi = grid_search.best_params_\n",
    "print(best_params_multi)\n",
    "\n",
    "best_model.save_model(\"best_xgb_model_multi_local.json\") \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9388ee6e-9a26-4647-95ea-8d70fe094761",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Showing XGBMulticlass\n",
    "\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Classes and numeric mapping\n",
    "class_names = ['foster', 'rescue', 'return_to_owner']\n",
    "n_classes = len(class_names)\n",
    "\n",
    "# Binarize the numeric y_test\n",
    "y_test_bin = label_binarize(y_test, classes=[0, 1, 2])\n",
    "\n",
    "# Get prediction probabilities\n",
    "y_score = best_model.predict_proba(X_test)\n",
    "\n",
    "# Compute ROC curve and AUC for each class\n",
    "fpr, tpr, roc_auc = {}, {}, {}\n",
    "for i in range(n_classes):\n",
    "    fpr[i], tpr[i], _ = roc_curve(y_test_bin[:, i], y_score[:, i])\n",
    "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "\n",
    "# Compute micro-average ROC and AUC\n",
    "fpr[\"micro\"], tpr[\"micro\"], _ = roc_curve(y_test_bin.ravel(), y_score.ravel())\n",
    "roc_auc[\"micro\"] = auc(fpr[\"micro\"], tpr[\"micro\"])\n",
    "\n",
    "# Plot all ROC curves\n",
    "plt.figure(figsize=(8, 6))\n",
    "for i, label in enumerate(class_names):\n",
    "    plt.plot(fpr[i], tpr[i], lw=2, label=f'ROC curve ({label}) (AUC = {roc_auc[i]:.2f})')\n",
    "\n",
    "plt.plot(fpr[\"micro\"], tpr[\"micro\"], color='deeppink', linestyle=':', linewidth=2,\n",
    "         label=f'Micro-average ROC (AUC = {roc_auc[\"micro\"]:.2f})')\n",
    "\n",
    "plt.plot([0, 1], [0, 1], 'k--', lw=2)\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Multiclass ROC Curve')\n",
    "plt.legend(loc='lower right')\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4df532fe-4521-419b-9253-813df6d8e20a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "aa2b73c2-8e28-476f-aa73-07157e4f94be",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Training for XGBoost Endpoint Multiclass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f628c75-1888-4c13-ba82-ea967d91fa81",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remembering our columns so we can pass the right features to XGboost\n",
    "\n",
    "all_columns = multi_predicted_df_test.columns.tolist()\n",
    "print(all_columns)\n",
    "print(\"Total columns for los_predicted structure:\", len(all_columns))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3478289-e144-4cb4-ae5f-075820c1da18",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data Prep from above work to S3 so sagemaker can access\n",
    "\n",
    "# Setup\n",
    "import boto3\n",
    "import sagemaker\n",
    "from sagemaker.estimator import Estimator\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "# SageMaker setup\n",
    "session = sagemaker.Session()\n",
    "role = \"arn:aws:iam::917456409349:role/Sagemaker_Execution_Role\"\n",
    "\n",
    "bucket = \"xgb-los-multi\"\n",
    "prefix = \"xgb-multi-code\"\n",
    "data_prefix = f\"{prefix}/data\"\n",
    "\n",
    "# Feature and target columns\n",
    "feature_columns_multi = [\n",
    "    'Encoded-animal_type', \n",
    "    'Encoded-primary_breed_harmonized', \n",
    "    'Encoded-primary_color_harmonized', \n",
    "    'Encoded-sex', \n",
    "    'Encoded-intake_type_harmonized', \n",
    "    'Encoded-Is_returned', \n",
    "    'Encoded-has_name', \n",
    "    'Encoded-is_mix',\n",
    "    'age_months',    \n",
    "    'Num_returned', \n",
    "    'stay_length_days',\n",
    "    'min_height', \n",
    "    'max_height',\n",
    "    'min_weight', \n",
    "    'max_weight', \n",
    "    'min_expectancy', \n",
    "    'max_expectancy',\n",
    "    'grooming_frequency_value', \n",
    "    'shedding_value', \n",
    "    'energy_level_value',\n",
    "    'trainability_value', \n",
    "    'demeanor_value'\n",
    "]\n",
    "\n",
    "target_column = \"Encoded-non_adopted_label\"\n",
    "\n",
    "# Function to reorder columns for SageMaker (target first)\n",
    "def prepare_for_sagemaker(df):\n",
    "    df = df[[target_column] + feature_columns_multi]\n",
    "    return df\n",
    "\n",
    "# Prepare train/validate/test\n",
    "train_df = prepare_for_sagemaker(multi_predicted_df_train)\n",
    "val_df = prepare_for_sagemaker(multi_predicted_df_validate)\n",
    "test_df = prepare_for_sagemaker(multi_predicted_df_test)\n",
    "\n",
    "# Save as CSV (no header/index)\n",
    "train_df.to_csv(\"train.csv\", header=False, index=False)\n",
    "val_df.to_csv(\"validation.csv\", header=False, index=False)\n",
    "test_df.to_csv(\"test.csv\", header=False, index=False)\n",
    "\n",
    "# Upload to S3\n",
    "s3 = boto3.client(\"s3\")\n",
    "s3.upload_file(\"train.csv\", bucket, f\"{data_prefix}/train.csv\")\n",
    "s3.upload_file(\"validation.csv\", bucket, f\"{data_prefix}/validation.csv\")\n",
    "s3.upload_file(\"test.csv\", bucket, f\"{data_prefix}/test.csv\")\n",
    "\n",
    "print(\" Uploaded to:\")\n",
    "print(f\"s3://{bucket}/{data_prefix}/train.csv\")\n",
    "print(f\"s3://{bucket}/{data_prefix}/validation.csv\")\n",
    "print(f\"s3://{bucket}/{data_prefix}/test.csv\")\n",
    "\n",
    "train_s3_path = f\"s3://{bucket}/{data_prefix}/train.csv\"\n",
    "val_s3_path = f\"s3://{bucket}/{data_prefix}/validation.csv\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37570e77-539e-4277-8a9f-b717ed85fdc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now we access S3 to run our endpoint and deployment training\n",
    "\n",
    "#container image for XGBoost\n",
    "\n",
    "container = sagemaker.image_uris.retrieve(\"xgboost\", session.boto_region_name, version=\"1.5-1\")\n",
    "\n",
    "#{'gamma': 0, 'learning_rate': 0.1, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 50, 'subsample': 0.6}\n",
    "\n",
    "import sagemaker\n",
    "from sagemaker.estimator import Estimator\n",
    "from sagemaker.inputs import TrainingInput\n",
    "\n",
    "\n",
    "# Create estimator for multiclass problem\n",
    "xgb_estimator_multi = Estimator(\n",
    "    image_uri=container,\n",
    "    role=role,\n",
    "    instance_count=1,\n",
    "    instance_type=\"ml.m5.xlarge\",\n",
    "    volume_size=10,\n",
    "    max_run=3600,\n",
    "    output_path=f\"s3://{bucket}/{prefix}/output\",\n",
    "    sagemaker_session=session\n",
    ")\n",
    "\n",
    "# Hyperparameters for multiclass, adjusting a bit from pretraining in effort to improve model based on test cases\n",
    "#from student team in \"ShelterData_ML_Final.ipynb\"\n",
    "\n",
    "xgb_estimator_multi.set_hyperparameters(\n",
    "    objective=\"multi:softprob\",  # Multiclass classification\n",
    "    num_class=3,                # foster, rescue, return_to_owner\n",
    "    eval_metric=\"mlogloss\",     # Multiclass metric\n",
    "    eta=0.1,                    # learning rate\n",
    "    max_depth=3,\n",
    "    min_child_weight=1,\n",
    "    subsample=0.6,\n",
    "    gamma=0,\n",
    "    num_round=50,               # number of boosting rounds\n",
    "    seed=42\n",
    ")\n",
    "\n",
    "print(\"Starting training job for multiclass model...\")\n",
    "xgb_estimator_multi.fit({\n",
    "    \"train\": TrainingInput(train_s3_path, content_type=\"text/csv\"),\n",
    "    \"validation\": TrainingInput(val_s3_path, content_type=\"text/csv\")\n",
    "})\n",
    "\n",
    "print(\"Model stored at:\",f\"s3://{bucket}/{prefix}/output\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88fa6f27-8bb3-4d2a-bdce-6a681faf462b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Model stored at:\",f\"s3://{bucket}/{prefix}/output\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c82ca6f6-9b9a-4f57-8590-f783b2860a2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Last, we deploy\n",
    "\n",
    "from sagemaker.serializers import CSVSerializer\n",
    "\n",
    "\n",
    "print(\" Deploying endpoint...\")\n",
    "xgb_predictor_multi = xgb_estimator_multi.deploy(\n",
    "    initial_instance_count=1,\n",
    "    instance_type=\"ml.m5.large\",\n",
    "    endpoint_name=\"xgb-multi-endpoint3\"\n",
    ")\n",
    "\n",
    "# Configure predictor\n",
    "xgb_predictor_multi.serializer = CSVSerializer()\n",
    "print (\"endpoint is live:\",xgb_predictor_multi.endpoint_name)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8a37ffa-d20a-447e-80b0-910e3bbf8cea",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Inspect multi_predicted_Test_DF\n",
    "#See all columns\n",
    "all_columns = multi_predicted_df_test.columns.tolist()\n",
    "print(all_columns)\n",
    "print(\"Total columns:\", len(all_columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76d39488-d386-49fd-b42b-84952a16fdd6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "multi_predicted_df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e07fcbac-247f-47bb-a6e6-771b565bdf01",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now we test the endpoint using multi_predicted_df_test \n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sagemaker.serializers import CSVSerializer\n",
    "from sagemaker.predictor import Predictor\n",
    "\n",
    "#setup\n",
    "endpoint_name = \"xgb-multi-endpoint3\"\n",
    "xgb_predictor_multi = Predictor(endpoint_name)\n",
    "xgb_predictor_multi.serializer = CSVSerializer()\n",
    "\n",
    "#FEatures\n",
    "feature_columns_multi = [\n",
    "    'Encoded-animal_type',\n",
    "    'Encoded-primary_breed_harmonized',\n",
    "    'Encoded-primary_color_harmonized',\n",
    "    'Encoded-sex',\n",
    "    'Encoded-intake_type_harmonized',\n",
    "    'Encoded-Is_returned',\n",
    "    'Encoded-has_name',\n",
    "    'Encoded-is_mix',\n",
    "    'age_months',\n",
    "    'Num_returned',\n",
    "    'stay_length_days',\n",
    "    'min_height',\n",
    "    'max_height',\n",
    "    'min_weight',\n",
    "    'max_weight',\n",
    "    'min_expectancy',\n",
    "    'max_expectancy',\n",
    "    'grooming_frequency_value',\n",
    "    'shedding_value',\n",
    "    'energy_level_value',\n",
    "    'trainability_value',\n",
    "    'demeanor_value'\n",
    "]\n",
    "\n",
    "target_column = \"Encoded-non_adopted_label\"\n",
    "\n",
    "#  Prepare test data\n",
    "df_test = multi_predicted_df_test.copy()\n",
    "df_test = df_test[df_test[target_column].isin([0, 1, 2])]  # Filter out 'other' or null\n",
    "\n",
    "X_test = df_test[feature_columns_multi].fillna(0)\n",
    "y_test = df_test[target_column].astype(int).tolist()\n",
    "\n",
    "print(f\" Using {len(X_test)} rows and {len(feature_columns_multi)} features for inference\")\n",
    "\n",
    "#  Predict from endpoint in batches ---\n",
    "predictions = []\n",
    "batch_size = 100\n",
    "\n",
    "for i in range(0, X_test.shape[0], batch_size):\n",
    "    batch = X_test.iloc[i:i+batch_size]\n",
    "    payload = \"\\n\".join([\",\".join(map(str, row)) for row in batch.to_numpy()])\n",
    "    \n",
    "    if i == 0:\n",
    "        print(\" Sample payload being sent:\", payload.split(\"\\n\")[0])\n",
    "    \n",
    "    response = xgb_predictor_multi.predict(payload)\n",
    "    decoded = response.decode(\"utf-8\").strip()\n",
    "    \n",
    "    if decoded:\n",
    "        # Split lines, map to class with highest probability\n",
    "        probs = [list(map(float, line.split(\",\"))) for line in decoded.split(\"\\n\")]\n",
    "        preds = [int(np.argmax(p)) for p in probs]\n",
    "        predictions.extend(preds)\n",
    "    else:\n",
    "        print(f\"Empty response for batch {i}-{i+batch_size}\")\n",
    "\n",
    "print(f\"Predictions received: {len(predictions)} rows\")\n",
    "\n",
    "# --- Evaluation ---\n",
    "labels = ['foster', 'rescue', 'return_to_owner']\n",
    "print(\"\\n Classification Report:\")\n",
    "print(classification_report(y_test, predictions, target_names=labels))\n",
    "\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(confusion_matrix(y_test, predictions))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
