{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "460b8784-8247-4169-903a-86e594590475",
   "metadata": {},
   "source": [
    "## Building our Container Testing Scripts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00e590d6-27af-4d72-8819-03aa323e4de2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.processing import ProcessingInput, ProcessingOutput\n",
    "import sagemaker\n",
    "import time\n",
    "from sagemaker.processing import ScriptProcessor, ProcessingInput, ProcessingOutput\n",
    "import sagemaker\n",
    "import time\n",
    "\n",
    "\n",
    "\n",
    "sess = sagemaker.Session()\n",
    "role = sagemaker.get_execution_role()\n",
    "\n",
    "image_uri = '917456409349.dkr.ecr.us-east-2.amazonaws.com/my-custom-sklearn'\n",
    "\n",
    "script_processor = ScriptProcessor(\n",
    "    role=role,\n",
    "    image_uri=image_uri,\n",
    "    command=['python3'],\n",
    "    instance_count=1,\n",
    "    instance_type='ml.m5.xlarge',\n",
    "    max_runtime_in_seconds=1200,\n",
    "    sagemaker_session=sess,\n",
    ")\n",
    "\n",
    "job_name = f\"shap-process-{int(time.time())}\"\n",
    "\n",
    "script_processor.run(\n",
    "    code='shap_process.py',\n",
    "    inputs=[\n",
    "        ProcessingInput(\n",
    "            source='s3://dockerevalcontainer/processing/input/model/model.tar.gz',\n",
    "            destination='/opt/ml/processing/input/model/'\n",
    "        ),\n",
    "        ProcessingInput(\n",
    "            source='s3://dockerevalcontainer/processing/input/data/scored.csv',\n",
    "            destination='/opt/ml/processing/input/data/'\n",
    "        ),\n",
    "    ],\n",
    "    outputs=[\n",
    "        ProcessingOutput(\n",
    "            source='/opt/ml/processing/output/',\n",
    "            destination='s3://dockerevalcontainer/processing/output/'\n",
    "        )\n",
    "    ],\n",
    "    job_name=job_name,\n",
    "    wait=True,\n",
    "    logs=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "848addeb-9441-44f1-8a21-33309ab6ea09",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "\n",
    "sm_client = boto3.client('sagemaker')\n",
    "\n",
    "response = sm_client.list_processing_jobs(\n",
    "    SortBy='CreationTime',\n",
    "    SortOrder='Descending',\n",
    "    MaxResults=5\n",
    ")\n",
    "\n",
    "for job in response['ProcessingJobSummaries']:\n",
    "    print(job['ProcessingJobName'], job['ProcessingJobStatus'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99a5ca7b-ad62-4020-a5b6-c57297519100",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "\n",
    "sm = boto3.client('sagemaker')\n",
    "job_name = 'shap-process-1753319283'  # replace with actual job name as needed\n",
    "\n",
    "response = sm.describe_processing_job(ProcessingJobName=job_name)\n",
    "print(\"Status:\", response['ProcessingJobStatus'])\n",
    "print(\"FailureReason:\", response.get('FailureReason', 'N/A'))\n",
    "print(\"SecondaryStatus:\", response.get('SecondaryStatus', 'N/A'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36df5834-f4c1-4d76-b77a-06b3c18482f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "\n",
    "s3 = boto3.client('s3')\n",
    "bucket = 'dockerevalcontainer'\n",
    "prefix = 'processing/output/'\n",
    "\n",
    "response = s3.list_objects_v2(Bucket=bucket, Prefix=prefix)\n",
    "print(\"Files in output prefix:\")\n",
    "for obj in response.get('Contents', []):\n",
    "    print(obj['Key'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b1c50a3-79c5-4535-b4aa-a6ee98f07cc3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-26T18:07:10.872787Z",
     "iopub.status.busy": "2025-07-26T18:07:10.872479Z",
     "iopub.status.idle": "2025-07-26T18:07:10.875428Z",
     "shell.execute_reply": "2025-07-26T18:07:10.874959Z",
     "shell.execute_reply.started": "2025-07-26T18:07:10.872766Z"
    }
   },
   "source": [
    "## Helper code below for uploading files to test locally from s3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbd1270a-7071-4291-bbfd-d2116e1741f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Testing input files are identical for ingestion\n",
    "\n",
    "# import pandas as pd\n",
    "\n",
    "# file1 = 'scored.csv'\n",
    "# file2 = 'sample_data_output.csv'\n",
    "\n",
    "# df1 = pd.read_csv(file1)\n",
    "# df2 = pd.read_csv(file2)\n",
    "\n",
    "# # Compare shapes first\n",
    "# if df1.shape != df2.shape:\n",
    "#     print(f\"Files differ in shape: {df1.shape} vs {df2.shape}\")\n",
    "# else:\n",
    "#     # Compare data content\n",
    "#     if df1.equals(df2):\n",
    "#         print(\"Files are identical.\")\n",
    "#     else:\n",
    "#         print(\"Files have the same shape but differ in content.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da00c4fa-ee0d-4988-b79e-83d47c35221c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Testing model run locally and put through shap in scikit vs end to end output below\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "file1 = 'final_with_shap.csv'\n",
    "file2 = 'final_with_shap_fullendtoend.csv'\n",
    "\n",
    "df1 = pd.read_csv(file1)\n",
    "df2 = pd.read_csv(file2)\n",
    "\n",
    "# Compare shapes first\n",
    "if df1.shape != df2.shape:\n",
    "    print(f\"Files differ in shape: {df1.shape} vs {df2.shape}\")\n",
    "else:\n",
    "    # Compare data content\n",
    "    if df1.equals(df2):\n",
    "        print(\"Files are identical.\")\n",
    "    else:\n",
    "        print(\"Files have the same shape but differ in content.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c31c60c5-0b70-4826-8a66-de78bcecb920",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Local File upload from S3 for working in Sagemaker\n",
    "\n",
    "bucket = \"sagemaker-us-east-2-917456409349\" #update as needed\n",
    "key = \"sagemaker/adoption/output_zone_sample/sample_data_output.csv\"#update as needed\n",
    "\n",
    "s3 = boto3.client('s3')\n",
    "\n",
    "response = s3.get_object(Bucket=bucket, Key=key)\n",
    "content = response['Body'].read()\n",
    "\n",
    "df = pd.read_csv(io.BytesIO(content))\n",
    "\n",
    "\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05c7e73f-59bd-48bd-a355-e31426e47328",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export DataFrame \n",
    "output_path = \"sample_data_output.csv\"\n",
    "df.to_csv(output_path, index=False)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2dcfc9c-14c7-4a09-b62e-e65a4e9ab2a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Testing our csv locally with shap process.py before uploading\n",
    "\n",
    "model_tar_path = 'model.tar.gz'  #local tar\n",
    "input_csv_path = 'sample_data_output.csv'  #local file\n",
    "output_csv_path = 'final_with_shap.csv'  # ocal final with shap\n",
    "\n",
    "#Running shap_process.py (have to do this in bash)\n",
    "#python shap_process.py\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de572226-7310-4650-bf54-32204874aa9b",
   "metadata": {},
   "source": [
    "## Testing locally and remotely as needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61d2cbd7-4d88-4f41-ae50-8013f45e441e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#We've now run a full end to end so testing what worked in shap_process.py locally works in pipeline\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "file1 = 'final_with_shap_local.csv'\n",
    "file2 = 'final_with_shap.csv'\n",
    "\n",
    "df1 = pd.read_csv(file1)\n",
    "df2 = pd.read_csv(file2)\n",
    "\n",
    "# Compare shapes first\n",
    "if df1.shape != df2.shape:\n",
    "    print(f\"Files differ in shape: {df1.shape} vs {df2.shape}\")\n",
    "else:\n",
    "    # Compare data content\n",
    "    if df1.equals(df2):\n",
    "        print(\"Files are identical.\")\n",
    "    else:\n",
    "        print(\"Files have the same shape but differ in content.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46f0d111-fa79-4f59-9ad5-9d460b62d42b",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Checking performance at end of full pipeline via docker etc.\n",
    "\n",
    "#Showing performance\n",
    "import pandas as pd\n",
    "import boto3\n",
    "from io import BytesIO\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, f1_score, roc_auc_score,\n",
    "    roc_curve, confusion_matrix, ConfusionMatrixDisplay\n",
    ")\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load ground truth from S3\n",
    "bucket = \"sagemaker-us-east-2-917456409349\"\n",
    "key = \"sagemaker/adoption/golden_record/df_cat_dog_harmonized_Sample_With_Outcome.csv\"\n",
    "\n",
    "s3 = boto3.client('s3')\n",
    "obj = s3.get_object(Bucket=bucket, Key=key)\n",
    "df_true = pd.read_csv(BytesIO(obj['Body'].read()))\n",
    "\n",
    "# Convert ground truth to binary: adopted=1 else 0\n",
    "df_true['true_label'] = (df_true['outcome_type_harmonized_grouped'] == 'adopted').astype(int)\n",
    "\n",
    "# Load predicted local file\n",
    "df_pred = pd.read_csv(\"final_with_shap.csv\") ###Uploaded from output landing zone, can update for whateve file we want to check\n",
    "\n",
    "# Merge on primary_key\n",
    "df_merged = pd.merge(df_true[['primary_key', 'true_label']], df_pred[['primary_key', 'predicted_label', 'predicted_proba']], on='primary_key')\n",
    "\n",
    "# Extract arrays\n",
    "y_true = df_merged['true_label']\n",
    "y_pred = df_merged['predicted_label']\n",
    "y_proba = df_merged['predicted_proba']\n",
    "\n",
    "# Calculate metrics\n",
    "accuracy = accuracy_score(y_true, y_pred)\n",
    "precision = precision_score(y_true, y_pred, zero_division=0)\n",
    "recall = recall_score(y_true, y_pred, zero_division=0)\n",
    "f1 = f1_score(y_true, y_pred, zero_division=0)\n",
    "auc = roc_auc_score(y_true, y_proba)\n",
    "\n",
    "print(f\"Scored file shape: {df_pred.shape}\")\n",
    "print(f\"Golden file shape: {df_true.shape}\")\n",
    "print(f\"Merged shape: {df_merged.shape}\\n\")\n",
    "\n",
    "print(\"PERFORMANCE METRICS\")\n",
    "print(f\" Accuracy:  {accuracy:.4f}\")\n",
    "print(f\" Precision: {precision:.4f}\")\n",
    "print(f\" Recall:    {recall:.4f}\")\n",
    "print(f\" F1 Score:  {f1:.4f}\")\n",
    "print(f\" AUC:       {auc:.4f}\")\n",
    "\n",
    "# Confusion matrix\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "disp.plot()\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.show()\n",
    "\n",
    "# ROC Curve\n",
    "fpr, tpr, thresholds = roc_curve(y_true, y_proba)\n",
    "plt.plot(fpr, tpr, label=f'AUC = {auc:.4f}')\n",
    "plt.plot([0, 1], [0, 1], linestyle='--', color='gray')\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.title(\"ROC Curve\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(\"Test Classification Report for adoption score (XGBoost:\")\n",
    "print(classification_report(\n",
    "    y_true, \n",
    "    y_pred, \n",
    "    labels=[0, 1],                   # Predict label order: adopted (1), non-adopted (0)\n",
    "    target_names=['non-adopted', 'adopted'],  \n",
    "    digits=6\n",
    "))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9242ae1-1ab4-4845-9052-1ee77100a121",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Local and remote are identical, and model performance is as expected so pipeline is working correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4daf3a32-5bcb-4707-bbe6-7c5b32d144b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Testing updated\n",
    "#We've now run a full end to end so testing what worked in shap_process.py locally works in pipeline\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "file1 = 'final_with_shap_ratios_Update.csv'\n",
    "file2 = 'final_with_shap_ratios.csv'\n",
    "\n",
    "df1 = pd.read_csv(file1)\n",
    "df2 = pd.read_csv(file2)\n",
    "\n",
    "# Compare shapes first\n",
    "if df1.shape != df2.shape:\n",
    "    print(f\"Files differ in shape: {df1.shape} vs {df2.shape}\")\n",
    "else:\n",
    "    # Compare data content\n",
    "    if df1.equals(df2):\n",
    "        print(\"Files are identical.\")\n",
    "    else:\n",
    "        print(\"Files have the same shape but differ in content.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e5ebc03-7d4c-4f94-a42c-e083778bc890",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
