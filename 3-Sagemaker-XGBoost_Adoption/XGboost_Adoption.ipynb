{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3de571b-50c8-45ab-9c3c-f4d6346769f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Note: Used references from Billy Fong (TA for DS210), as well as AWS references:\n",
    "#https://sagemaker-examples.readthedocs.io/en/latest/introduction_to_amazon_algorithms/xgboost_abalone/xgboost_managed_spot_training.html\n",
    "#Note: This code was run previously, with a later limited edits to clean up formatting and comments. Final code not re-run to avoid any conflicts with existing model files in S3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "339d0899-5ba8-44d3-93c9-ef83d86df1bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Note: only needed on initial install\n",
    "#!pip install --upgrade sagemaker"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50b09da4-68fd-4b38-9fdd-8337b445659f",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Setting up environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56e19ead-24e3-4049-a218-11450e1ef27b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing key packages\n",
    "import io\n",
    "import os\n",
    "import boto3\n",
    "import sagemaker\n",
    "import time\n",
    "import botocore\n",
    "from sagemaker import get_execution_role, image_uris, model_uris, script_uris, hyperparameters\n",
    "from sagemaker.estimator import Estimator\n",
    "from sagemaker.utils import name_from_base\n",
    "from sagemaker.tuner import HyperparameterTuner\n",
    "from time import gmtime, strftime\n",
    "import matplotlib as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f8c2b28-3442-4e30-96a6-c4beb4cf27ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Setting up\n",
    "\n",
    "role = sagemaker.get_execution_role()\n",
    "boto_session = boto3.Session()\n",
    "region = boto_session.region_name\n",
    "sess = sagemaker.Session(boto_session=boto_session)\n",
    "\n",
    "print(\"Role:\", role)\n",
    "print(\"Region:\", region)\n",
    "print(\"SageMaker Session Region:\", sess.boto_region_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f36d60fc-5c16-4585-b75d-7bebe5728407",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Setting up Bucket Links/Info\n",
    "\n",
    "\n",
    "bucket='sagemaker-us-east-2-917456409349'\n",
    "s3_bucket_prefix= \"sagemaker/adoption/Code/\"\n",
    "prefix = f\"{bucket}/{s3_bucket_prefix}\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea0aa1e4-cc7f-465a-aed5-7cbcec1c1ed7",
   "metadata": {},
   "outputs": [],
   "source": [
    "prefix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01705819-81d0-4503-b609-29f341c15ea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set Container\n",
    "container = sagemaker.image_uris.retrieve(\"xgboost\", region, \"1.7-1\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d74a9d64-e69e-404d-8fda-292741c0b482",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Ingesting Data and splitting/training/test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "653e822e-aae7-47a5-ba5b-46ea9b764dae",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load Source file to do encoding and split train/test\n",
    "\n",
    "import boto3\n",
    "import pandas as pd\n",
    "import io\n",
    "\n",
    "bucket = \"sagemaker-us-east-2-917456409349\"\n",
    "key = \"sagemaker/adoption/golden_record/df_cat_dog_harmonized.csv\"\n",
    "\n",
    "s3_client = boto3.client(\"s3\")\n",
    "obj = s3_client.get_object(Bucket=bucket, Key=key)\n",
    "df = pd.read_csv(io.BytesIO(obj['Body'].read()))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5ea376e-5346-425e-a1b6-e352b57024d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Length prededupe\n",
    "\n",
    "np.shape(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73e28d97-5a47-4d2a-a21b-f49be6889a4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Deduping\n",
    "\n",
    "\n",
    "# Drop duplicates, keeping the last record for each animal_id\n",
    "df_deduped = df.drop_duplicates(subset='primary_key', keep='last')\n",
    "\n",
    "print(\"Original rows:\", len(df))\n",
    "print(\"After deduplication:\", len(df_deduped))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b27d82e3-0e84-4c3b-a8ae-202bed70c748",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Setting to Deduped so rest of code works\n",
    "\n",
    "df = df_deduped.copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a21b0e79-baa3-424e-9b10-ea9ec81b4437",
   "metadata": {},
   "outputs": [],
   "source": [
    "#See all columns\n",
    "all_columns = df.columns.tolist()\n",
    "print(all_columns)\n",
    "print(\"Total columns:\", len(all_columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27124f25-8ff2-4e9c-9581-8c14d7431d0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Setting outcome_type_final_grouped to be first for Sagemaker Training\n",
    "\n",
    "column = 'outcome_type_harmonized_grouped'\n",
    "cols = [column] + [col for col in df.columns if col != column]\n",
    "df = df[cols]\n",
    "\n",
    "#Check new order\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e54cb119-6dff-43d6-a3e0-619bccd9ee5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Adding Custom Train/Test/Split\n",
    "def assign_split(row):\n",
    "    if row['outcome_year'] <= 2022:\n",
    "        return \"train\"\n",
    "    elif row['outcome_year'] in [2023, 2024]:\n",
    "        return \"validate\"\n",
    "    elif row['outcome_year'] == 2025:\n",
    "        return \"test\"\n",
    "    else:\n",
    "        return \"exclude\"  # fallback for unexpected years\n",
    "\n",
    "df['split'] = df.apply(assign_split, axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e583e582-526d-46b5-b564-6efdc5b44574",
   "metadata": {},
   "outputs": [],
   "source": [
    "#See all columns\n",
    "all_columns = df.columns.tolist()\n",
    "print(all_columns)\n",
    "print(\"Total columns:\", len(all_columns))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b39ae0b-630a-4936-ac2f-f115170e674d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Naming features to keep and drop if needed, but won't as keeping standard format of xlsx.\n",
    "features_to_keep = ['outcome_type_harmonized_grouped','animal_type', 'primary_breed_harmonized', 'primary_color_harmonized',\n",
    "    'sex', 'intake_type_harmonized',\n",
    "    'Is_returned', 'has_name', 'is_mix', 'Num_returned', 'age_months','stay_length_days', 'min_height', 'max_height',\n",
    "    'min_weight', 'max_weight', 'min_expectancy', 'max_expectancy',\n",
    "    'grooming_frequency_value', 'shedding_value', 'energy_level_value',\n",
    "    'trainability_value', 'demeanor_value'\n",
    "]\n",
    "\n",
    "# # Trim the DataFrame to only those columns\n",
    "# df = df[features_to_keep].copy()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c772ba19-b6d7-4ba5-884d-016509e93174",
   "metadata": {},
   "outputs": [],
   "source": [
    "#See all columns\n",
    "all_columns = df.columns.tolist()\n",
    "print(all_columns)\n",
    "print(\"Total columns:\", len(all_columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3feb0f92-005a-4aec-9431-10d7108912f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c06b9339-b1aa-495c-b491-ec7c409ee071",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pre-encoding Adoption\n",
    "df['outcome_type_harmonized_grouped'] = (df['outcome_type_harmonized_grouped'] == 'adopted').astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f71b9b26-f13c-4334-bf5f-3cd23aeb6d53",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2521895a-b853-411f-8cef-af6a171c67b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Encoding\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Copy original DataFrame\n",
    "encoded_df = df.copy()\n",
    "\n",
    "# Specific columns you want to encode\n",
    "columns_to_encode = [\n",
    "    'animal_type', 'primary_breed_harmonized', 'primary_color_harmonized',\n",
    "    'sex', 'intake_type_harmonized',\n",
    "    'Is_returned', 'has_name', 'is_mix'\n",
    "]\n",
    "\n",
    "# Dictionary to store label encoders (optional: for inverse transform or saving later)\n",
    "le_dict = {}\n",
    "\n",
    "# Apply label encoding to specified columns, save in new columns\n",
    "for col in columns_to_encode:\n",
    "    le = LabelEncoder()\n",
    "    encoded_col_name = f\"Encoded-{col}\"\n",
    "    encoded_df[encoded_col_name] = le.fit_transform(encoded_df[col].astype(str))\n",
    "    le_dict[col] = le\n",
    "\n",
    "# Fill missing age_months with median\n",
    "median_age = encoded_df['age_months'].median()\n",
    "encoded_df['age_months'] = encoded_df['age_months'].fillna(median_age)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dbe5b56-afad-4c30-ae69-c414aaa39886",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.shape(encoded_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75d63828-4db3-46cf-8ded-c0518b735e21",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Seeing encoded table\n",
    "encoded_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5f3c072-01d8-4860-8184-019327bcd9aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving Encoding\n",
    "import pickle\n",
    "\n",
    "with open(\"label_encoders.pkl\", \"wb\") as f:\n",
    "    pickle.dump(le_dict, f)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc8f84c9-21db-4a11-934d-19cde912848c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#See all columns\n",
    "all_columns = encoded_df.columns.tolist()\n",
    "print(all_columns)\n",
    "print(\"Total columns:\", len(all_columns))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3b189bb-0041-4ce3-92f4-133b20874561",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b3ae6ae-3dc1-4549-93fd-dd7a860e9dbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.shape(encoded_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a10c4609-e50c-4214-8d22-906ee64f7bcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting for training\n",
    "\n",
    "df_train = encoded_df[encoded_df['split'] == 'train']\n",
    "df_test = encoded_df[encoded_df['split'] == 'test']\n",
    "df_validate = encoded_df[encoded_df['split'] == 'validate']\n",
    "# Save each to CSV (no index)\n",
    "df_train.to_csv(\"train.csv\", index=False)\n",
    "df_test.to_csv(\"test.csv\", index=False)\n",
    "df_validate.to_csv(\"validate.csv\", index=False)\n",
    "\n",
    "# Output sizes\n",
    "print(\"Train rows:\", len(df_train))\n",
    "print(\"Test rows:\", len(df_test))\n",
    "print(\"Validate rows:\", len(df_validate))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c952e831-db68-4a78-ac70-18529500b041",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "397131bf-6010-4b4b-a3bc-6283265933d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e132c526-ed35-44ea-b555-c73d5ca107da",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_validate.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b11c14e7-2442-47d8-a1ca-32d02bf720b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d77d5cec-4197-4ce0-9f48-f1ceb3f0fefa",
   "metadata": {},
   "outputs": [],
   "source": [
    "prefix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a6a11cb-4440-4d22-b56d-15c0a56a6c7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "key"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc512b92-1bd6-43c5-bf7e-84d24b14aefe",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Training Model Locally\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84c98a5d-08fa-4df0-8761-6a12bad31bf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# efine feature columns \n",
    "feature_columns = [\n",
    "'Encoded-animal_type', \n",
    "    'Encoded-primary_breed_harmonized', \n",
    "    'Encoded-primary_color_harmonized', \n",
    "    'Encoded-sex', \n",
    "    'Encoded-intake_type_harmonized', \n",
    "    'Encoded-Is_returned', \n",
    "    'Encoded-has_name', \n",
    "    'Encoded-is_mix',\n",
    "    'age_months',    \n",
    "    'Num_returned', \n",
    "    'stay_length_days', \n",
    "    'min_height', \n",
    "    'max_height',\n",
    "    'min_weight', \n",
    "    'max_weight', \n",
    "    'min_expectancy', \n",
    "    'max_expectancy',\n",
    "    'grooming_frequency_value', \n",
    "    'shedding_value', \n",
    "    'energy_level_value',\n",
    "    'trainability_value', \n",
    "    'demeanor_value'\n",
    "]\n",
    "\n",
    "# prepare datasets using only selected features\n",
    "X_train = df_train[feature_columns]\n",
    "y_train = df_train['outcome_type_harmonized_grouped']\n",
    "\n",
    "X_val = df_validate[feature_columns]\n",
    "y_val = df_validate['outcome_type_harmonized_grouped']\n",
    "\n",
    "X_test = df_test[feature_columns]\n",
    "y_test = df_test['outcome_type_harmonized_grouped']\n",
    "\n",
    "# define model\n",
    "xgb_model = XGBClassifier(\n",
    "    max_depth=5,\n",
    "    learning_rate=0.2,\n",
    "    gamma=4,\n",
    "    min_child_weight=6,\n",
    "    subsample=0.7,\n",
    "    objective=\"binary:logistic\",\n",
    "    eval_metric=\"logloss\",\n",
    "    n_estimators=50,\n",
    "    n_jobs=-1,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# train model\n",
    "xgb_model.fit(X_train, y_train)\n",
    "\n",
    "# tredict and evaluate\n",
    "def evaluate_performance(X, y_true, dataset_name):\n",
    "    y_pred = xgb_model.predict(X)\n",
    "    print(f\"\\n{dataset_name} Set Performance:\")\n",
    "    print(classification_report(y_true, y_pred))\n",
    "    \n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "    disp.plot(cmap='Blues')\n",
    "    plt.title(f\"{dataset_name} confusion matrix\")\n",
    "    plt.show()\n",
    "\n",
    "# Run evaluations\n",
    "evaluate_performance(X_train, y_train, \"Training\")\n",
    "evaluate_performance(X_val, y_val, \"Validation\")\n",
    "evaluate_performance(X_test, y_test, \"Test\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3cb0c09-a55b-4743-9304-ee7619d182a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Running AMT to see if can improve Test performance\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "feature_columns = [\n",
    "'Encoded-animal_type', \n",
    "    'Encoded-primary_breed_harmonized', \n",
    "    'Encoded-primary_color_harmonized', \n",
    "    'Encoded-sex', \n",
    "    'Encoded-intake_type_harmonized', \n",
    "    'Encoded-Is_returned', \n",
    "    'Encoded-has_name', \n",
    "    'Encoded-is_mix',\n",
    "    'age_months',    \n",
    "    'Num_returned', \n",
    "    'stay_length_days', \n",
    "    'min_height', \n",
    "    'max_height',\n",
    "    'min_weight', \n",
    "    'max_weight', \n",
    "    'min_expectancy', \n",
    "    'max_expectancy',\n",
    "    'grooming_frequency_value', \n",
    "    'shedding_value', \n",
    "    'energy_level_value',\n",
    "    'trainability_value', \n",
    "    'demeanor_value'\n",
    "]\n",
    "\n",
    "\n",
    "# prepare datasets using only selected features\n",
    "X_train = df_train[feature_columns]\n",
    "y_train = df_train['outcome_type_harmonized_grouped']\n",
    "\n",
    "X_val = df_validate[feature_columns]\n",
    "y_val = df_validate['outcome_type_harmonized_grouped']\n",
    "\n",
    "X_test = df_test[feature_columns]\n",
    "y_test = df_test['outcome_type_harmonized_grouped']\n",
    "\n",
    "# Combine train and val for GridSearchCV\n",
    "X_trainval = pd.concat([X_train, X_val])\n",
    "y_trainval = pd.concat([y_train, y_val])\n",
    "\n",
    "# Define parameter grid\n",
    "param_grid = {\n",
    "    'max_depth': [3, 5, 7],\n",
    "    'learning_rate': [0.05, 0.1, 0.2],\n",
    "    'gamma': [0, 2, 4],\n",
    "    'min_child_weight': [1, 4, 6],\n",
    "    'subsample': [0.6, 0.8, 1.0],\n",
    "    'n_estimators': [50, 100],\n",
    "}\n",
    "\n",
    "# Initialize model\n",
    "xgb_base = XGBClassifier(\n",
    "    objective='binary:logistic',\n",
    "    eval_metric='logloss',\n",
    "    n_jobs=-1,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Grid search with 3-fold CV\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=xgb_base,\n",
    "    param_grid=param_grid,\n",
    "    scoring='f1',\n",
    "    cv=3,\n",
    "    verbose=1,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# Fit grid search\n",
    "grid_search.fit(X_trainval, y_trainval)\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "print(\"Best parameters found:\", grid_search.best_params_)\n",
    "\n",
    "# Evaluation function\n",
    "def evaluate_performance(X, y_true, dataset_name):\n",
    "    y_pred = best_model.predict(X)\n",
    "    print(f\"\\n{dataset_name} Set Performance:\")\n",
    "    print(classification_report(y_true, y_pred))\n",
    "\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "    disp.plot(cmap='Blues')\n",
    "    plt.title(f\"{dataset_name} Confusion Matrix\")\n",
    "    plt.show()\n",
    "\n",
    "# Run evaluations\n",
    "evaluate_performance(X_train, y_train, \"Training\")\n",
    "evaluate_performance(X_val, y_val, \"Validation\")\n",
    "evaluate_performance(X_test, y_test, \"Test\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "984232d2-9ab4-4933-820f-24309d97ac01",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Outputting Best Parameters, saving model \n",
    "\n",
    "best_params = grid_search.best_params_\n",
    "print(best_params)\n",
    "\n",
    "best_model.save_model(\"best_xgb_model_local.json\") \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a44b163d-1b61-4c09-aea9-936db16fcf3b",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Sagemaker Model Parameter and Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6dd1971-ffd3-4d5d-8baf-4b3204d382dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Uploading to S3, withhead or index\n",
    "\n",
    "import io\n",
    "import boto3\n",
    "\n",
    "bucket_name = bucket\n",
    "base_prefix = prefix\n",
    "s3_client = boto3.client(\"s3\")\n",
    "\n",
    "# Reorder columns to ensure label is first\n",
    "def reorder_columns(df, label_col):\n",
    "    cols = [label_col] + [col for col in df.columns if col != label_col]\n",
    "    return df[cols]\n",
    "\n",
    "# Helper to upload a DataFrame as CSV to S3 (with header and index)\n",
    "def upload_df_to_s3(df, path, label_col):\n",
    "    df = reorder_columns(df, label_col)\n",
    "\n",
    "    csv_buffer = io.StringIO()\n",
    "    df.to_csv(csv_buffer, index=True, header=True)  #  keep index and header\n",
    "    s3_client.put_object(Bucket=bucket_name, Key=path, Body=csv_buffer.getvalue())\n",
    "    print(f\"Uploaded to s3://{bucket_name}/{path} (with header and index)\")\n",
    "\n",
    "# Upload each split\n",
    "label_col = 'outcome_type_harmonized_grouped'\n",
    "\n",
    "upload_df_to_s3(df_train, f\"{base_prefix}/train/train_data.csv\", label_col)\n",
    "upload_df_to_s3(df_test, f\"{base_prefix}/test/test_data.csv\", label_col)\n",
    "upload_df_to_s3(df_validate, f\"{base_prefix}/val/validate_data.csv\", label_col)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c3ef111-23dd-45ca-a330-a774199b33b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set Parameters for Binary Classification\n",
    "\n",
    "hyperparameters = {\n",
    "    \"max_depth\": \"5\",\n",
    "    \"eta\": \"0.2\",                   \n",
    "    \"gamma\": \"4\",\n",
    "    \"min_child_weight\": \"6\",\n",
    "    \"subsample\": \"0.7\",\n",
    "    \"objective\": \"binary:logistic\",\n",
    "    \"eval_metric\": \"logloss\",\n",
    "    \"num_round\": \"50\",      \n",
    "    \"verbosity\": \"2\",\n",
    "    \"seed\": \"42\",\n",
    "    \"scale_pos_weight\": \"2.16\"  \n",
    "}\n",
    "# Set output\n",
    "instance_type = \"ml.m5.4xlarge\"\n",
    "output_path = \"s3://{}/{}/output\".format(bucket, prefix)\n",
    "content_type = \"csv\"\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf12bcc0-a315-42ed-b473-1d730ccf98dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import pandas as pd\n",
    "import io\n",
    "\n",
    "# S3 path\n",
    "bucket = \"sagemaker-us-east-2-917456409349\"\n",
    "input_key = \"sagemaker/adoption/train/train_data.csv\"\n",
    "output_key = \"sagemaker/adoption/train/train_data_filtered/train_data.csv\" #EDIT-Remember to update this if simplifying pipeline\n",
    "\n",
    "# Define target and features\n",
    "target_column = 'outcome_type_harmonized_grouped'\n",
    "feature_columns = [\n",
    "'Encoded-animal_type', \n",
    "    'Encoded-primary_breed_harmonized', \n",
    "    'Encoded-primary_color_harmonized', \n",
    "    'Encoded-sex', \n",
    "    'Encoded-intake_type_harmonized', \n",
    "    'Encoded-Is_returned', \n",
    "    'Encoded-has_name', \n",
    "    'Encoded-is_mix',\n",
    "    'age_months',    \n",
    "    'Num_returned', \n",
    "    'stay_length_days', \n",
    "    'min_height', \n",
    "    'max_height',\n",
    "    'min_weight', \n",
    "    'max_weight', \n",
    "    'min_expectancy', \n",
    "    'max_expectancy',\n",
    "    'grooming_frequency_value', \n",
    "    'shedding_value', \n",
    "    'energy_level_value',\n",
    "    'trainability_value', \n",
    "    'demeanor_value'\n",
    "]\n",
    "\n",
    "columns_to_upload = [target_column] + feature_columns  # label first\n",
    "\n",
    "# Load CSV from S3\n",
    "s3 = boto3.client(\"s3\")\n",
    "response = s3.get_object(Bucket=bucket, Key=input_key)\n",
    "body = response[\"Body\"].read()\n",
    "df = pd.read_csv(io.BytesIO(body))\n",
    "\n",
    "#drop the first column if it's an unnamed index\n",
    "if df.columns[0].lower().startswith('unnamed') or df.columns[0] == '':\n",
    "    df = df.iloc[:, 1:]\n",
    "\n",
    "# Filter and drop rows with missing target\n",
    "df_filtered = df[columns_to_upload].dropna(subset=[target_column])\n",
    "\n",
    "# Write to memory (no header, no index)\n",
    "csv_buffer = io.StringIO()\n",
    "df_filtered.to_csv(csv_buffer, index=False, header=False)\n",
    "\n",
    "# Upload to S3\n",
    "s3.put_object(Bucket=bucket, Key=output_key, Body=csv_buffer.getvalue())\n",
    "print(f\" Uploaded clean CSV to s3://{bucket}/{output_key} (no index, no header)\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b29016c-8725-45b4-b787-fc63cf743828",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Training using predefined hyperparameters\n",
    "#Edit: Referenced code from example XGBoost Model Abalone\n",
    "#https://sagemaker-examples.readthedocs.io/en/latest/introduction_to_amazon_algorithms/xgboost_abalone/xgboost_managed_spot_training.html\n",
    "#7/4/25\n",
    "\n",
    "import time\n",
    "from sagemaker.inputs import TrainingInput\n",
    "from sagemaker.estimator import Estimator\n",
    "import sagemaker\n",
    "\n",
    "# Generate a timestamped job name\n",
    "job_name = f\"adoption-xgboost-{time.strftime('%Y-%m-%d-%H-%M-%S', time.gmtime())}\"\n",
    "print(\"Training job:\", job_name)\n",
    "\n",
    "# Spot instance configuration\n",
    "use_spot_instances = True\n",
    "max_run = 3600  # max time for actual training\n",
    "max_wait = 7200 if use_spot_instances else None  # max total time (includes waiting for spot)\n",
    "\n",
    "# Checkpoint path (optional for spot)\n",
    "checkpoint_s3_uri = (\n",
    "    f\"s3://{bucket}/{prefix}/checkpoints/{job_name}\" if use_spot_instances else None\n",
    ")\n",
    "print(\"Checkpoint path:\", checkpoint_s3_uri)\n",
    "\n",
    "# Define SageMaker estimator\n",
    "estimator = Estimator(\n",
    "    image_uri=container,\n",
    "    role=role,\n",
    "    instance_count=1,\n",
    "    instance_type=instance_type,\n",
    "    volume_size=5,  # GB\n",
    "    output_path=output_path,\n",
    "    sagemaker_session=sagemaker.Session(),\n",
    "    use_spot_instances=use_spot_instances,\n",
    "    max_run=max_run,\n",
    "    max_wait=max_wait,\n",
    "    checkpoint_s3_uri=checkpoint_s3_uri,\n",
    "    hyperparameters=hyperparameters\n",
    ")\n",
    "\n",
    "# Training input from S3 (folder-style path)\n",
    "train_input = TrainingInput(\n",
    "    s3_data=f\"s3://{bucket}/sagemaker/adoption/train/train_data_filtered\",\n",
    "    content_type=\"text/csv\"\n",
    ")\n",
    "\n",
    "# Launch training job\n",
    "estimator.fit({\"train\": train_input}, job_name=job_name)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1830e7d-4ed5-45af-85a6-d36079e35131",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Testing Sagemaker Endpoint Model - ONLY DO THIS TO TEST MODEL IS WORKING BEFORE TESTING ENDPOINT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ae80886-183b-429e-9323-625875b94272",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "\n",
    "s3 = boto3.client('s3')\n",
    "bucket = 'sagemaker-us-east-2-917456409349'\n",
    "key = 'sagemaker/adoption/output/adoption-xgboost-2025-07-17-00-53-45/output/model.tar.gz' \n",
    "local_path = 'model.tar.gz'\n",
    "\n",
    "# Download model.tar.gz\n",
    "s3.download_file(bucket, key, local_path)\n",
    "print(\" model.tar.gz downloaded locally.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9022b738-87de-4e9c-965a-b8999cb9a983",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tarfile\n",
    "\n",
    "# Extract model.tar.gz\n",
    "with tarfile.open(\"model.tar.gz\") as tar:\n",
    "    tar.extractall(\"model_dir\")\n",
    "\n",
    "print(\" Extracted model files:\")\n",
    "!ls model_dir\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ac77ac5-9bc7-4cfe-bf49-ef49357c7b5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import xgboost as xgb\n",
    "\n",
    "# Load trained model\n",
    "booster = xgb.Booster()\n",
    "booster.load_model(\"model_dir/xgboost-model\")  # path from SageMaker tar.gz\n",
    "\n",
    "# Manually assign feature names \n",
    "booster.feature_names = feature_columns\n",
    "\n",
    "# Plot feature importance\n",
    "xgb.plot_importance(booster, importance_type='weight', show_values=True)\n",
    "plt.title(\"Feature Importance (by frequency)\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba8965b5-5996-48c2-9adf-2ece26ad8265",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Seeing all columns so I know which ones to drop\n",
    "\n",
    "df_train.columns.tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b238589-975f-4c30-b400-6b25f35e4ae5",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "## Local Testing of tar.gz model\n",
    "\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import classification_report, roc_auc_score\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load trained XGBoost model\n",
    "booster = xgb.Booster()\n",
    "booster.load_model(\"model_dir/xgboost-model\")\n",
    "\n",
    "# Define feature columns (must match training)\n",
    "feature_columns = ['Encoded-animal_type', \n",
    "    'Encoded-primary_breed_harmonized', \n",
    "    'Encoded-primary_color_harmonized', \n",
    "    'Encoded-sex', \n",
    "    'Encoded-intake_type_harmonized', \n",
    "    'Encoded-Is_returned', \n",
    "    'Encoded-has_name', \n",
    "    'Encoded-is_mix',\n",
    "    'age_months',    \n",
    "    'Num_returned', \n",
    "    'stay_length_days', \n",
    "    'min_height', \n",
    "    'max_height',\n",
    "    'min_weight', \n",
    "    'max_weight', \n",
    "    'min_expectancy', \n",
    "    'max_expectancy',\n",
    "    'grooming_frequency_value', \n",
    "    'shedding_value', \n",
    "    'energy_level_value',\n",
    "    'trainability_value', \n",
    "    'demeanor_value'\n",
    "] \n",
    "\n",
    "target_column = 'outcome_type_harmonized_grouped'\n",
    "\n",
    "# Prepare datasets\n",
    "X_train = df_train[feature_columns]\n",
    "y_train = df_train[target_column].astype(int)\n",
    "\n",
    "X_val = df_validate[feature_columns]\n",
    "y_val = df_validate[target_column].astype(int)\n",
    "\n",
    "X_test = df_test[feature_columns]\n",
    "y_test = df_test[target_column].astype(int)\n",
    "\n",
    "# Convert to DMatrix with feature names\n",
    "dtrain = xgb.DMatrix(X_train, label=y_train, feature_names=feature_columns)\n",
    "dval = xgb.DMatrix(X_val, label=y_val, feature_names=feature_columns)\n",
    "dtest = xgb.DMatrix(X_test, label=y_test, feature_names=feature_columns)\n",
    "\n",
    "# Predict probabilities\n",
    "y_train_pred = booster.predict(dtrain)\n",
    "y_val_pred = booster.predict(dval)\n",
    "y_test_pred = booster.predict(dtest)\n",
    "\n",
    "# Convert to binary predictions\n",
    "y_train_pred_labels = (y_train_pred >= 0.5).astype(int)\n",
    "y_val_pred_labels = (y_val_pred >= 0.5).astype(int)\n",
    "y_test_pred_labels = (y_test_pred >= 0.5).astype(int)\n",
    "\n",
    "# Evaluate\n",
    "print(\"Training Set Performance:\")\n",
    "print(classification_report(y_train, y_train_pred_labels, zero_division=0))\n",
    "print(f\"AUC: {roc_auc_score(y_train, y_train_pred):.4f}\")\n",
    "\n",
    "print(\"Validation Set Performance:\")\n",
    "print(classification_report(y_val, y_val_pred_labels, zero_division=0))\n",
    "print(f\"AUC: {roc_auc_score(y_val, y_val_pred):.4f}\")\n",
    "\n",
    "print(\"Test Set Performance:\")\n",
    "print(classification_report(y_test, y_test_pred_labels, zero_division=0))\n",
    "print(f\"AUC: {roc_auc_score(y_test, y_test_pred):.4f}\")\n",
    "\n",
    "# Distributions\n",
    "print(\"\\nPredicted labels distribution:\")\n",
    "print(\"Train:\", np.bincount(y_train_pred_labels))\n",
    "print(\"Val:  \", np.bincount(y_val_pred_labels))\n",
    "print(\"Test: \", np.bincount(y_test_pred_labels))\n",
    "\n",
    "print(\"\\nTrue labels:\")\n",
    "print(\"Train:\", np.bincount(y_train))\n",
    "print(\"Val:  \", np.bincount(y_val))\n",
    "print(\"Test: \", np.bincount(y_test))\n",
    "\n",
    "# Feature Importance\n",
    "booster.feature_names = feature_columns\n",
    "xgb.plot_importance(booster, importance_type='gain', show_values=True)\n",
    "plt.title(\"Feature Importance (Gain)\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b225dece-cf27-4bb9-b94c-230a0ae046c7",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Setting up Endpoint - ONLY DO WHEN SETTING UP ENDPOINT OTHERWISE SKIP OVER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "874cf2d6-b8e1-485e-88a6-17dc0b74784e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#EDIT/NOTE: Do this after locally testing Sagemaker Model for effectiveness.\n",
    "\n",
    "from sagemaker.serverless import ServerlessInferenceConfig\n",
    "from sagemaker.model import Model\n",
    "\n",
    "serverless_config = ServerlessInferenceConfig(\n",
    "    memory_size_in_mb=6144,\n",
    "    max_concurrency=3,\n",
    ")\n",
    "\n",
    "model = Model(\n",
    "    image_uri=container,\n",
    "    model_data=estimator.model_data,\n",
    "    role=role,\n",
    "    sagemaker_session=sagemaker.Session()\n",
    ")\n",
    "\n",
    "predictor = model.deploy(\n",
    "    serverless_inference_config=serverless_config\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dadf704d-f1dd-4b51-88ba-f2e0f39eadf9",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Endpoint Testing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f019d91-9fb1-4f5d-8bd5-211877dd7200",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Note: Make sure to manually update endpoint name as needed\n",
    "endpoint_name = 'sagemaker-xgboost-2025-07-17-01-08-23-168'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5879c4ed-d3cf-4d79-aa16-772ac0659b7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Note: Files sourced in S3 Have no Headers but columns are: feature_columns = ['Encoded-animal_type', \n",
    "#     'Encoded-primary_breed_harmonized', \n",
    "#     'Encoded-primary_color_harmonized', \n",
    "#     'Encoded-sex', \n",
    "#     'Encoded-intake_type_harmonized', \n",
    "#     'Encoded-Is_returned', \n",
    "#     'Encoded-has_name', \n",
    "#     'Encoded-is_mix',\n",
    "#     'age_months',    \n",
    "#     'Num_returned', \n",
    "#     'stay_length_days', \n",
    "#     'min_height', \n",
    "#     'max_height',\n",
    "#     'min_weight', \n",
    "#     'max_weight', \n",
    "#     'min_expectancy', \n",
    "#     'max_expectancy',\n",
    "#     'grooming_frequency_value', \n",
    "#     'shedding_value', \n",
    "#     'energy_level_value',\n",
    "#     'trainability_value', \n",
    "#     'demeanor_value'\n",
    "# ] \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c986722-f877-4c19-b297-92e22f14fb90",
   "metadata": {},
   "outputs": [],
   "source": [
    "prefix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fe7ab30-8c49-4b3d-a9b0-aada6367eaf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "097e2844-5822-4313-becb-9e77b9fab316",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.metrics import classification_report, roc_auc_score, RocCurveDisplay\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "\n",
    "# CONFIGURATION\n",
    "\n",
    "MODEL_PATH = \"model_dir/xgboost-model\"  # path to SageMaker model\n",
    "OUTPUT_PREDICTIONS_CSV = \"model_predictions.csv\"  # output predictions file\n",
    "\n",
    "# Feature list (must match model training)\n",
    "feature_columns = ['Encoded-animal_type', \n",
    "    'Encoded-primary_breed_harmonized', \n",
    "    'Encoded-primary_color_harmonized', \n",
    "    'Encoded-sex', \n",
    "    'Encoded-intake_type_harmonized', \n",
    "    'Encoded-Is_returned', \n",
    "    'Encoded-has_name', \n",
    "    'Encoded-is_mix',\n",
    "    'age_months',    \n",
    "    'Num_returned', \n",
    "    'stay_length_days', \n",
    "    'min_height', \n",
    "    'max_height',\n",
    "    'min_weight', \n",
    "    'max_weight', \n",
    "    'min_expectancy', \n",
    "    'max_expectancy',\n",
    "    'grooming_frequency_value', \n",
    "    'shedding_value', \n",
    "    'energy_level_value',\n",
    "    'trainability_value', \n",
    "    'demeanor_value'\n",
    "] \n",
    "target_column = 'outcome_type_harmonized_grouped'\n",
    "\n",
    "# LOAD MODEL\n",
    "\n",
    "booster = xgb.Booster()\n",
    "booster.load_model(MODEL_PATH)\n",
    "\n",
    "\n",
    "# PREPARE DATASETS\n",
    "\n",
    "X_train = df_train[feature_columns]\n",
    "y_train = df_train[target_column].astype(int)\n",
    "\n",
    "X_val = df_validate[feature_columns]\n",
    "y_val = df_validate[target_column].astype(int)\n",
    "\n",
    "X_test = df_test[feature_columns]\n",
    "y_test = df_test[target_column].astype(int)\n",
    "\n",
    "# Convert to DMatrix\n",
    "dtrain = xgb.DMatrix(X_train, label=y_train, feature_names=feature_columns)\n",
    "dval = xgb.DMatrix(X_val, label=y_val, feature_names=feature_columns)\n",
    "dtest = xgb.DMatrix(X_test, label=y_test, feature_names=feature_columns)\n",
    "\n",
    "\n",
    "# PREDICTIONS\n",
    "\n",
    "y_train_proba = booster.predict(dtrain)\n",
    "y_val_proba = booster.predict(dval)\n",
    "y_test_proba = booster.predict(dtest)\n",
    "\n",
    "# Binary classification threshold\n",
    "threshold = 0.5\n",
    "y_train_pred = (y_train_proba >= threshold).astype(int)\n",
    "y_val_pred = (y_val_proba >= threshold).astype(int)\n",
    "y_test_pred = (y_test_proba >= threshold).astype(int)\n",
    "\n",
    "\n",
    "# PERFORMANCE REPORTS\n",
    "\n",
    "def evaluate_performance(y_true, y_pred, y_proba, name):\n",
    "    print(f\"\\n{name} Performance:\")\n",
    "    print(classification_report(y_true, y_pred, zero_division=0))\n",
    "    auc = roc_auc_score(y_true, y_proba)\n",
    "    print(f\"AUC: {auc:.4f}\")\n",
    "    return auc\n",
    "\n",
    "auc_train = evaluate_performance(y_train, y_train_pred, y_train_proba, \"TRAIN\")\n",
    "auc_val = evaluate_performance(y_val, y_val_pred, y_val_proba, \"VALIDATION\")\n",
    "auc_test = evaluate_performance(y_test, y_test_pred, y_test_proba, \"TEST\")\n",
    "\n",
    "\n",
    "# ROC CURVES\n",
    "\n",
    "plt.figure()\n",
    "RocCurveDisplay.from_predictions(y_train, y_train_proba, name=\"Train\")\n",
    "RocCurveDisplay.from_predictions(y_val, y_val_proba, name=\"Validation\")\n",
    "RocCurveDisplay.from_predictions(y_test, y_test_proba, name=\"Test\")\n",
    "plt.title(\"ROC Curves (Train / Val / Test)\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# FEATURE IMPORTANCE\n",
    "\n",
    "booster.feature_names = feature_columns\n",
    "xgb.plot_importance(booster, importance_type='gain', show_values=True)\n",
    "plt.title(\"Feature Importance (Gain)\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# SAVE PREDICTIONS TO CSV\n",
    "\n",
    "predictions_df = pd.DataFrame({\n",
    "    \"Dataset\": ([\"Train\"] * len(y_train)) + ([\"Validation\"] * len(y_val)) + ([\"Test\"] * len(y_test)),\n",
    "    \"True_Label\": np.concatenate([y_train, y_val, y_test]),\n",
    "    \"Predicted_Label\": np.concatenate([y_train_pred, y_val_pred, y_test_pred]),\n",
    "    \"Predicted_Probability\": np.concatenate([y_train_proba, y_val_proba, y_test_proba])\n",
    "})\n",
    "predictions_df.to_csv(OUTPUT_PREDICTIONS_CSV, index=False)\n",
    "print(f\"\\n Predictions saved to {OUTPUT_PREDICTIONS_CSV}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32a71398-f2e2-4042-ab31-0c8e5bc12957",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Testing on Train Data\n",
    "\n",
    "import boto3\n",
    "import pandas as pd\n",
    "import io\n",
    "import numpy as np\n",
    "from sagemaker.predictor import Predictor\n",
    "from sagemaker.serializers import CSVSerializer\n",
    "from sagemaker.deserializers import JSONDeserializer\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Configuration\n",
    "train_key = f\"{prefix}/train/train_data.csv\"\n",
    "batch_size = 500  # adjust for performance\n",
    "\n",
    "# Predictor setup\n",
    "predictor = Predictor(\n",
    "    endpoint_name=endpoint_name,\n",
    "    serializer=CSVSerializer(),\n",
    "    deserializer=JSONDeserializer()\n",
    ")\n",
    "\n",
    "# Load train data from S3\n",
    "s3_client = boto3.client(\"s3\")\n",
    "obj = s3_client.get_object(Bucket=bucket, Key=train_key)\n",
    "df_full = pd.read_csv(io.BytesIO(obj[\"Body\"].read()), header=0)  # assumes CSV has header\n",
    "\n",
    "# Define features used by model\n",
    "feature_columns =['Encoded-animal_type', \n",
    "    'Encoded-primary_breed_harmonized', \n",
    "    'Encoded-primary_color_harmonized', \n",
    "    'Encoded-sex', \n",
    "    'Encoded-intake_type_harmonized', \n",
    "    'Encoded-Is_returned', \n",
    "    'Encoded-has_name', \n",
    "    'Encoded-is_mix',\n",
    "    'age_months',    \n",
    "    'Num_returned', \n",
    "    'stay_length_days', \n",
    "    'min_height', \n",
    "    'max_height',\n",
    "    'min_weight', \n",
    "    'max_weight', \n",
    "    'min_expectancy', \n",
    "    'max_expectancy',\n",
    "    'grooming_frequency_value', \n",
    "    'shedding_value', \n",
    "    'energy_level_value',\n",
    "    'trainability_value', \n",
    "    'demeanor_value'\n",
    "] \n",
    "\n",
    "# Label\n",
    "target_column = 'outcome_type_harmonized_grouped'\n",
    "\n",
    "# Extract label and features\n",
    "y_true = df_full[target_column].values\n",
    "X = df_full[feature_columns]\n",
    "\n",
    "# Batch inference\n",
    "y_pred = []\n",
    "for i in range(0, len(X), batch_size):\n",
    "    batch = X.iloc[i:i + batch_size]\n",
    "    payload = \"\\n\".join([\",\".join(map(str, row)) for row in batch.values])\n",
    "    response = predictor.predict(payload)\n",
    "    scores = [p['score'] for p in response['predictions']]\n",
    "    y_pred.extend([round(score) for score in scores])\n",
    "\n",
    "# Append predictions\n",
    "df_full[\"predicted_outcome\"] = y_pred\n",
    "\n",
    "# Evaluate\n",
    "print(\"Train Set Performance:\")\n",
    "print(classification_report(y_true, y_pred, zero_division=0))\n",
    "\n",
    "# (Optional) Save locally or to S3\n",
    "#df_full.to_csv(\"train_with_predictions.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44b3d71d-bafb-46b7-bf65-76c8d1c691b9",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Endpoint Testing sending a Payload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aef70d33-11c7-4958-9f17-995194078ea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sagemaker.predictor import Predictor\n",
    "from sagemaker.serializers import CSVSerializer\n",
    "from sagemaker.deserializers import JSONDeserializer\n",
    "\n",
    "# Config\n",
    "local_csv_path = \"test.csv\"\n",
    "batch_size = 500\n",
    "# Define features used by model\n",
    "feature_columns =['Encoded-animal_type', \n",
    "    'Encoded-primary_breed_harmonized', \n",
    "    'Encoded-primary_color_harmonized', \n",
    "    'Encoded-sex', \n",
    "    'Encoded-intake_type_harmonized', \n",
    "    'Encoded-Is_returned', \n",
    "    'Encoded-has_name', \n",
    "    'Encoded-is_mix',\n",
    "    'age_months',    \n",
    "    'Num_returned', \n",
    "    'stay_length_days', \n",
    "    'min_height', \n",
    "    'max_height',\n",
    "    'min_weight', \n",
    "    'max_weight', \n",
    "    'min_expectancy', \n",
    "    'max_expectancy',\n",
    "    'grooming_frequency_value', \n",
    "    'shedding_value', \n",
    "    'energy_level_value',\n",
    "    'trainability_value', \n",
    "    'demeanor_value'\n",
    "] \n",
    "\n",
    "\n",
    "# Label\n",
    "target_column = 'outcome_type_harmonized_grouped'\n",
    "\n",
    "\n",
    "# Predictor\n",
    "predictor = Predictor(\n",
    "    endpoint_name=endpoint_name,\n",
    "    serializer=CSVSerializer(),\n",
    "    deserializer=JSONDeserializer()\n",
    ")\n",
    "\n",
    "# Load and prepare data\n",
    "df_full = pd.read_csv(local_csv_path)\n",
    "X = df_full[feature_columns]\n",
    "\n",
    "# Predict in batches\n",
    "preds = []\n",
    "for i in range(0, len(X), batch_size):\n",
    "    batch = X.iloc[i:i + batch_size]\n",
    "    payload = \"\\n\".join([\",\".join(map(str, row)) for row in batch.values])\n",
    "    response = predictor.predict(payload)\n",
    "    scores = [p[\"score\"] for p in response[\"predictions\"]]\n",
    "    preds.extend([round(score) for score in scores])\n",
    "\n",
    "# Append predictions to full data\n",
    "df_with_preds = df_full.copy()\n",
    "df_with_preds[\"predicted_outcome\"] = preds\n",
    "\n",
    "# Save to file\n",
    "df_with_preds.to_csv(\"test_with_predictions_endpointpayload.csv\", index=False)\n",
    "print(\" Saved test_with_predictions_endpointpayload.csv with headers and predictions.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71977e07-dbd9-4dad-85f0-bb99045b470f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay, roc_auc_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load CSV\n",
    "df = pd.read_csv(\"test_with_predictions_endpointpayload.csv\")\n",
    "\n",
    "# True and predicted columns\n",
    "y_true = df['outcome_type_harmonized_grouped']\n",
    "y_pred = df['predicted_outcome']\n",
    "\n",
    "#If have probabilities, load them into an array (adjust column names)\n",
    "#For binary classification:\n",
    "#y_prob = df['prob_class1']\n",
    "\n",
    "# For multiclass, extract all probability columns\n",
    "prob_cols = [col for col in df.columns if col.startswith(\"prob_\")]\n",
    "y_prob = df[prob_cols].values  # shape: (n_samples, n_classes)\n",
    "\n",
    "# Compute metrics\n",
    "print(\" Classification Report:\")\n",
    "print(classification_report(y_true, y_pred, zero_division=0))\n",
    "\n",
    "# Confusion Matrix\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "labels = sorted(y_true.unique())\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=labels)\n",
    "disp.plot(cmap=\"Blues\", values_format=\"d\")\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.show()\n",
    "\n",
    "# # AUC Score (multiclass)\n",
    "# from sklearn.preprocessing import label_binarize\n",
    "\n",
    "# classes = sorted(y_true.unique())\n",
    "# y_true_bin = label_binarize(y_true, classes=classes)\n",
    "# auc = roc_auc_score(y_true_bin, y_prob, multi_class='ovr')\n",
    "# print(f\"ROC AUC (One-vs-Rest): {auc:.4f}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4667026-f126-45d6-8ccb-72f8aacc26fb",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Encoding Standardization for use on new csv."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "339d9f99-ed4d-4d83-88b2-5df91b188d5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "\n",
    "\n",
    "# Load saved encoders\n",
    "with open(\"label_encoders.pkl\", \"rb\") as f:\n",
    "    le_dict = pickle.load(f)\n",
    "\n",
    "# load csv\n",
    "df_test = pd.read_csv(\"test.csv\")\n",
    "\n",
    "# handle missing age months as above\n",
    "median_age = df_test[\"age_months\"].median()\n",
    "df_test[\"age_months\"] = df_test[\"age_months\"].fillna(median_age)\n",
    "\n",
    "#applying encodings\n",
    "categorical_cols = [col for col in df_test.columns if col not in ['age_months', 'shelter', 'split', 'outcome_type_harmonized_grouped']] #df['outcome_type_harmonized_grouped']\n",
    "\n",
    "for col in categorical_cols:\n",
    "    if col in le_dict:\n",
    "        le = le_dict[col]\n",
    "        known_classes = set(le.classes_)\n",
    "        df_test[col] = df_test[col].astype(str).apply(lambda x: le.transform([x])[0] if x in known_classes else -1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3a92505-0559-4427-bebb-3f6ffb4436fb",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "##  Set up CSV Lambda ingestion and encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c9969f0-9b41-4f1d-984b-30a1c1d79432",
   "metadata": {},
   "source": [
    "### Only do this once!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd7a08e8-ea21-455a-96b1-92b6a4aca4eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating a dictionary as lambda layer won't run with scikit\n",
    "import pickle\n",
    "import boto3\n",
    "import io\n",
    "\n",
    "# Load the sklearn-based encoders\n",
    "with open(\"label_encoders.pkl\", \"rb\") as f:\n",
    "    le_dict = pickle.load(f)\n",
    "\n",
    "# Convert each LabelEncoder to a plain dictionary\n",
    "clean_dict = {\n",
    "    col: dict(zip(le.classes_, le.transform(le.classes_)))\n",
    "    for col, le in le_dict.items()\n",
    "}\n",
    "\n",
    "# Serialize the clean dict (no sklearn)\n",
    "pkl_buffer = io.BytesIO()\n",
    "pickle.dump(clean_dict, pkl_buffer)\n",
    "pkl_buffer.seek(0)\n",
    "\n",
    "# Upload to S3\n",
    "s3 = boto3.client(\"s3\")\n",
    "s3.put_object(\n",
    "    Bucket=\"sagemaker-us-east-2-917456409349\",\n",
    "    Key=\"sagemaker/adoption/encoders_model_files/clean_label_encoders_dict.pkl\",\n",
    "    Body=pkl_buffer.getvalue()\n",
    ")\n",
    "\n",
    "print(\"Saved clean dictionary to S3 — no scikit-learn dependency.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0603de23-5cab-4ea7-a9d2-e2e506c735ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This ingests the sample data and applies encoding for testing\n",
    "\n",
    "import boto3\n",
    "import pandas as pd\n",
    "import io\n",
    "\n",
    "s3 = boto3.client('s3')\n",
    "\n",
    "bucket = \"sagemaker-us-east-2-917456409349\"\n",
    "key = \"sagemaker/adoption/landing_zone_sample/df_cat_dog_harmonized_Sample_No_Known_Outcome.csv\"\n",
    "\n",
    "response = s3.get_object(Bucket=bucket, Key=key)\n",
    "df = pd.read_csv(io.BytesIO(response['Body'].read()))\n",
    "\n",
    "print(\" Loaded sample data\")\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "045ca99b-c646-412d-a7e7-437d7cf1d61c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load Key Dictionary\n",
    "\n",
    "key_dict = \"sagemaker/adoption/encoders_model_files/clean_label_encoders_dict.pkl\"\n",
    "\n",
    "response = s3.get_object(Bucket=bucket, Key=key_dict)\n",
    "clean_dict = pickle.load(io.BytesIO(response['Body'].read()))\n",
    "\n",
    "print(\"Loaded clean label encoder dictionary\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02394bf4-e5c4-4e7d-b95f-25e34d95eaca",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TESTING before running dictionary encoding in lambda\n",
    "#Applies encoding from Dictionary against key data points\n",
    "\n",
    "columns_to_encode = [\n",
    "    'animal_type', 'primary_breed_harmonized', 'primary_color_harmonized',\n",
    "    'sex', 'intake_type_harmonized',\n",
    "    'Is_returned', 'has_name', 'is_mix'\n",
    "]\n",
    "\n",
    "# Apply mappings\n",
    "for col in columns_to_encode:\n",
    "    encoded_col = f\"Encoded-{col}\"\n",
    "    df[col] = df[col].astype(str).fillna('nan')  # Ensure alignment with dict\n",
    "    df[encoded_col] = df[col].map(clean_dict[col]).fillna(-1).astype(int)  # Handle any mismatches safely\n",
    "\n",
    "# Fill missing age_months with 48\n",
    "df['age_months'] = df['age_months'].fillna(48)\n",
    "\n",
    "print(\" Applied encodings and filled age_months\")\n",
    "df.head(300)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cb684f3-02e9-4aee-8525-ffa3f455baaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save to CSV locally or upload back to S3\n",
    "#This is encoded sample\n",
    "\n",
    "csv_buffer = io.StringIO()\n",
    "df.to_csv(csv_buffer, index=False)\n",
    "\n",
    "s3.put_object(\n",
    "    Bucket=bucket,\n",
    "    Key=\"sagemaker/adoption/encoded_zone_sample/df_cat_dog_harmonized_Sample_With_No_Known_Outcome_ENCODED_NONLAMBDA.csv\",\n",
    "    Body=csv_buffer.getvalue()\n",
    ")\n",
    "\n",
    "print(\" Uploaded encoded file to S3\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f3e742a-06fe-46c2-ac71-648c12ee1b5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import io\n",
    "\n",
    "# S3 paths\n",
    "bucket = \"sagemaker-us-east-2-917456409349\"\n",
    "encoding_key = \"sagemaker/adoption/encoders_model_files/clean_label_encoders_dict.pkl\"\n",
    "output_csv_key = \"sagemaker/adoption/encoded_zone_sample/df_cat_dog_harmonized_Sample_With_No_Known_Outcome_ENCODED.csv\"\n",
    "\n",
    "# Initialize S3 client\n",
    "s3 = boto3.client(\"s3\")\n",
    "\n",
    "# --- Load encoder dict ---\n",
    "encoding_obj = s3.get_object(Bucket=bucket, Key=encoding_key)\n",
    "clean_dict = pickle.load(io.BytesIO(encoding_obj['Body'].read()))\n",
    "\n",
    "# --- Load encoded CSV ---\n",
    "csv_obj = s3.get_object(Bucket=bucket, Key=output_csv_key)\n",
    "df_encoded = pd.read_csv(io.BytesIO(csv_obj['Body'].read()))\n",
    "\n",
    "# Columns to check\n",
    "columns_to_check = [\n",
    "    'animal_type', 'primary_breed_harmonized', 'primary_color_harmonized',\n",
    "    'sex', 'intake_type_harmonized', 'Is_returned', 'has_name', 'is_mix'\n",
    "]\n",
    "\n",
    "print(\" Checking columns...\")\n",
    "print(\"CSV Columns:\", df_encoded.columns.tolist())\n",
    "print(\"Encoder Dict Keys:\", list(clean_dict.keys()))\n",
    "\n",
    "summary = []\n",
    "\n",
    "for col in columns_to_check:\n",
    "    encoded_col = f\"Encoded-{col}\"\n",
    "    print(f\"\\n🔍 Checking column: {col}\")\n",
    "\n",
    "    if col not in df_encoded.columns:\n",
    "        print(f\" Raw column '{col}' missing in CSV\")\n",
    "        summary.append((col, \"Raw column missing\"))\n",
    "        continue\n",
    "\n",
    "    if encoded_col not in df_encoded.columns:\n",
    "        print(f\" Encoded column '{encoded_col}' missing in CSV\")\n",
    "        summary.append((col, \"Encoded column missing\"))\n",
    "        continue\n",
    "\n",
    "    # Build mapping from CSV\n",
    "    inferred_map = (\n",
    "        df_encoded[[col, encoded_col]]\n",
    "        .dropna()\n",
    "        .drop_duplicates()\n",
    "        .set_index(col)[encoded_col]\n",
    "        .to_dict()\n",
    "    )\n",
    "\n",
    "    # Encoder mapping\n",
    "    encoder_map = clean_dict.get(col, {})\n",
    "    if not encoder_map:\n",
    "        print(f\" No encoder mapping found for '{col}'\")\n",
    "        summary.append((col, \"Encoder missing\"))\n",
    "        continue\n",
    "\n",
    "    # Compare\n",
    "    mismatches = []\n",
    "    for val, encoded in inferred_map.items():\n",
    "        expected = encoder_map.get(val)\n",
    "        if expected != encoded:\n",
    "            mismatches.append((val, encoded, expected))\n",
    "\n",
    "    if mismatches:\n",
    "        print(f\" {len(mismatches)} mismatches found:\")\n",
    "        for val, actual, expected in mismatches[:10]:\n",
    "            print(f\"    Value: '{val}' → CSV: {actual}, Encoder: {expected}\")\n",
    "        summary.append((col, f\"{len(mismatches)} mismatches\"))\n",
    "    else:\n",
    "        print(\" All values match\")\n",
    "        summary.append((col, \"OK\"))\n",
    "\n",
    "# Summary\n",
    "print(\"\\n=== SUMMARY ===\")\n",
    "for col, status in summary:\n",
    "    print(f\"{col}: {status}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ada24871-7e17-4f16-a898-aad40fecc59d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Diagnostic on encoding \n",
    "import boto3\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import io\n",
    "\n",
    "# Setup\n",
    "bucket = \"sagemaker-us-east-2-917456409349\"\n",
    "raw_csv_key = \"sagemaker/adoption/landing_zone_sample/df_cat_dog_harmonized_Sample_No_Known_Outcome.csv\"\n",
    "dict_key = \"sagemaker/adoption/encoders_model_files/clean_label_encoders_dict.pkl\"\n",
    "\n",
    "# --- Load input CSV\n",
    "s3 = boto3.client(\"s3\")\n",
    "csv_obj = s3.get_object(Bucket=bucket, Key=raw_csv_key)\n",
    "df_raw = pd.read_csv(io.BytesIO(csv_obj['Body'].read()))\n",
    "\n",
    "# Load clean_dict.pkl \n",
    "dict_obj = s3.get_object(Bucket=bucket, Key=dict_key)\n",
    "clean_dict = pickle.load(io.BytesIO(dict_obj['Body'].read()))\n",
    "\n",
    "# Columns to test\n",
    "columns = [\n",
    "    'animal_type', 'primary_breed_harmonized', 'primary_color_harmonized',\n",
    "    'sex', 'intake_type_harmonized',\n",
    "    'Is_returned', 'has_name', 'is_mix'\n",
    "]\n",
    "\n",
    "# Compare encodability \n",
    "summary = {}\n",
    "\n",
    "for col in columns:\n",
    "    if col not in df_raw.columns:\n",
    "        print(f\" Column '{col}' not found in input.\")\n",
    "        continue\n",
    "\n",
    "    # Clean values\n",
    "    raw_vals = df_raw[col].fillna(\"Unknown\").astype(str).str.strip().str.lower()\n",
    "\n",
    "    # Dictionary keys\n",
    "    dict_keys = set(map(str.lower, clean_dict.get(col, {}).keys()))\n",
    "\n",
    "    # Determine unmapped values\n",
    "    unmapped = sorted(set(raw_vals) - dict_keys)\n",
    "\n",
    "    summary[col] = {\n",
    "        \"total_unique_values\": len(set(raw_vals)),\n",
    "        \"unmapped_count\": len(unmapped),\n",
    "        \"unmapped_values\": unmapped[:10]  # sample\n",
    "    }\n",
    "\n",
    "# --- Report ---\n",
    "for col, result in summary.items():\n",
    "    print(f\"\\n Column: {col}\")\n",
    "    print(f\"Total unique raw values: {result['total_unique_values']}\")\n",
    "    print(f\" Unmapped values: {result['unmapped_count']}\")\n",
    "    if result[\"unmapped_count\"] > 0:\n",
    "        print(\"   Sample unmapped values:\", result[\"unmapped_values\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52514738-06f0-45a2-b104-555ffbed3e2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Based on the above, we have no unmapped values and can proceed to layers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9185bd5-3b71-4bef-af1b-b031f8527f50",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Test end to End w Lambda Sample and Original Sample Output, Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dc639e9-17cf-44d4-b19a-64d91d6bbef2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checking Lambda Function works for Encoding by  comparing local and lambda encoded tables\n",
    "import boto3\n",
    "import pandas as pd\n",
    "import io\n",
    "\n",
    "# S3 details\n",
    "bucket = \"sagemaker-us-east-2-917456409349\"\n",
    "file1 = \"sagemaker/adoption/encoded_zone_sample/df_cat_dog_harmonized_Sample_With_No_Known_Outcome_ENCODED_NONLAMBDA.csv\"\n",
    "file2 = \"sagemaker/adoption/encoded_zone_sample/df_cat_dog_harmonized_Sample_With_No_Known_Outcome_ENCODED.csv\"\n",
    "\n",
    "# Initialize S3 client\n",
    "s3 = boto3.client('s3')\n",
    "\n",
    "def load_csv_from_s3(bucket, key):\n",
    "    obj = s3.get_object(Bucket=bucket, Key=key)\n",
    "    return pd.read_csv(io.BytesIO(obj['Body'].read()))\n",
    "\n",
    "# Load both files\n",
    "print(\" Loading files from S3...\")\n",
    "df1 = load_csv_from_s3(bucket, file1)\n",
    "df2 = load_csv_from_s3(bucket, file2)\n",
    "\n",
    "# Compare shape\n",
    "if df1.shape != df2.shape:\n",
    "    print(f\" Shape mismatch: {df1.shape} vs {df2.shape}\")\n",
    "else:\n",
    "    print(f\" Shape matches: {df1.shape}\")\n",
    "\n",
    "# Compare columns\n",
    "if list(df1.columns) != list(df2.columns):\n",
    "    print(\" Column mismatch\")\n",
    "    print(\"File 1 columns:\", df1.columns.tolist())\n",
    "    print(\"File 2 columns:\", df2.columns.tolist())\n",
    "else:\n",
    "    print(\" Columns match\")\n",
    "\n",
    "# Compare data\n",
    "if df1.equals(df2):\n",
    "    print(\" Tables are identical\")\n",
    "else:\n",
    "    # Find differences\n",
    "    diff_mask = df1 != df2\n",
    "    diff_count = diff_mask.sum().sum()\n",
    "    print(f\" Tables differ in {diff_count} cells\")\n",
    "\n",
    "    # Optionally, save diff rows\n",
    "    diff_rows = df1[diff_mask.any(axis=1)]\n",
    "    diff_rows.to_csv(\"differences.csv\", index=False)\n",
    "    print(\"Differences saved to differences.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bf2912d-561f-4e6e-8c48-37527a69cfc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checking Lambda generated encoding file that is scored for prediction vs endpointtested prediction\n",
    "#First we have to generate our comparison file and write to bucket\n",
    "import boto3\n",
    "import pandas as pd\n",
    "import io\n",
    "from sagemaker.predictor import Predictor\n",
    "from sagemaker.serializers import CSVSerializer\n",
    "from sagemaker.deserializers import JSONDeserializer\n",
    "\n",
    "# --- Config ---\n",
    "bucket = \"sagemaker-us-east-2-917456409349\"\n",
    "input_key = \"sagemaker/adoption/encoded_zone_sample/df_cat_dog_harmonized_Sample_With_No_Known_Outcome_ENCODED.csv\"\n",
    "output_key = \"sagemaker/adoption/output_zone_sample/sample_data_output_IPYNBDTESTEDREMOTE.csv\"\n",
    "endpoint_name = \"sagemaker-xgboost-2025-07-17-01-08-23-168\"\n",
    "batch_size = 500\n",
    "\n",
    "# --- Features used by model ---\n",
    "feature_columns = [\n",
    "    'Encoded-animal_type', \n",
    "    'Encoded-primary_breed_harmonized', \n",
    "    'Encoded-primary_color_harmonized', \n",
    "    'Encoded-sex', \n",
    "    'Encoded-intake_type_harmonized', \n",
    "    'Encoded-Is_returned', \n",
    "    'Encoded-has_name', \n",
    "    'Encoded-is_mix',\n",
    "    'age_months',    \n",
    "    'Num_returned', \n",
    "    'stay_length_days', \n",
    "    'min_height', \n",
    "    'max_height',\n",
    "    'min_weight', \n",
    "    'max_weight', \n",
    "    'min_expectancy', \n",
    "    'max_expectancy',\n",
    "    'grooming_frequency_value', \n",
    "    'shedding_value', \n",
    "    'energy_level_value',\n",
    "    'trainability_value', \n",
    "    'demeanor_value'\n",
    "]\n",
    "\n",
    "# --- Initialize S3 and Predictor ---\n",
    "s3 = boto3.client(\"s3\")\n",
    "predictor = Predictor(\n",
    "    endpoint_name=endpoint_name,\n",
    "    serializer=CSVSerializer(),\n",
    "    deserializer=JSONDeserializer() \n",
    ")\n",
    "\n",
    "# --- Load input file from S3 ---\n",
    "print(\"Loading input file from S3...\")\n",
    "obj = s3.get_object(Bucket=bucket, Key=input_key)\n",
    "df_full = pd.read_csv(io.BytesIO(obj[\"Body\"].read()))\n",
    "print(f\"Loaded {len(df_full)} rows from {input_key}\")\n",
    "\n",
    "# --- Prepare features ---\n",
    "X = df_full[feature_columns].fillna(0)\n",
    "\n",
    "# --- Predict in batches ---\n",
    "pred_probs = []\n",
    "for i in range(0, len(X), batch_size):\n",
    "    batch = X.iloc[i:i + batch_size]\n",
    "    payload = \"\\n\".join([\",\".join(map(str, row)) for row in batch.values])\n",
    "    response = predictor.predict(payload)\n",
    "    #  Extract \"score\" from JSON response\n",
    "    batch_scores = [pred[\"score\"] for pred in response[\"predictions\"]]\n",
    "    pred_probs.extend(batch_scores)\n",
    "    print(f\"Processed batch {i // batch_size + 1} ({len(batch)} rows)\")\n",
    "\n",
    "# --- Convert to hard labels ---\n",
    "pred_labels = [1 if p >= 0.5 else 0 for p in pred_probs]\n",
    "\n",
    "# --- Append predictions ---\n",
    "df_full[\"predicted_proba\"] = pred_probs\n",
    "df_full[\"predicted_label\"] = pred_labels\n",
    "\n",
    "# --- Save output to S3 ---\n",
    "csv_buffer = io.StringIO()\n",
    "df_full.to_csv(csv_buffer, index=False)\n",
    "s3.put_object(Bucket=bucket, Key=output_key, Body=csv_buffer.getvalue())\n",
    "print(f\" Predictions saved to s3://{bucket}/{output_key}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b204ec0f-b2f3-457a-934f-13f15a2a6c87",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Finally, comparing output tables and they're identical!!!\n",
    "\n",
    "\n",
    "import boto3\n",
    "import pandas as pd\n",
    "import io\n",
    "\n",
    "# --- Config ---\n",
    "bucket = \"sagemaker-us-east-2-917456409349\"\n",
    "file_a = \"sagemaker/adoption/output_zone_sample/sample_data_output_IPYNBDTESTEDREMOTE.csv\"  # Notebook-scored\n",
    "file_b = \"sagemaker/adoption/output_zone_sample/sample_data_output.csv\"  # Lambda/pipeline-scored\n",
    "\n",
    "s3 = boto3.client('s3')\n",
    "\n",
    "# --- Function to load CSV from S3 ---\n",
    "def load_csv(bucket, key):\n",
    "    obj = s3.get_object(Bucket=bucket, Key=key)\n",
    "    return pd.read_csv(io.BytesIO(obj['Body'].read()))\n",
    "\n",
    "# --- Load both files ---\n",
    "print(\" Loading files from S3...\")\n",
    "df_a = load_csv(bucket, file_a)\n",
    "df_b = load_csv(bucket, file_b)\n",
    "\n",
    "print(f\" File A ({file_a}): {df_a.shape} rows & columns\")\n",
    "print(f\" File B ({file_b}): {df_b.shape} rows & columns\")\n",
    "\n",
    "# --- Compare shape ---\n",
    "if df_a.shape != df_b.shape:\n",
    "    print(f\" Shape mismatch: {df_a.shape} vs {df_b.shape}\")\n",
    "else:\n",
    "    print(\" Shape matches\")\n",
    "\n",
    "# --- Compare column names ---\n",
    "if list(df_a.columns) != list(df_b.columns):\n",
    "    print(\" Column mismatch!\")\n",
    "    print(\"File A columns:\", df_a.columns.tolist())\n",
    "    print(\"File B columns:\", df_b.columns.tolist())\n",
    "else:\n",
    "    print(\" Columns match\")\n",
    "\n",
    "# --- Compare entire DataFrame ---\n",
    "if df_a.equals(df_b):\n",
    "    print(\" Tables are completely identical\")\n",
    "else:\n",
    "    # Detect differences\n",
    "    diff_mask = df_a != df_b\n",
    "    diff_count = diff_mask.sum().sum()\n",
    "    print(f\" Tables differ in {diff_count} cells\")\n",
    "\n",
    "    # Find rows with any difference\n",
    "    diff_rows = df_a[diff_mask.any(axis=1)]\n",
    "    print(f\" {len(diff_rows)} rows have differences\")\n",
    "\n",
    "    # Save differences locally and upload to S3\n",
    "    diff_file = \"differences.csv\"\n",
    "    diff_rows.to_csv(diff_file, index=False)\n",
    "    s3.put_object(Bucket=bucket, Key=\"sagemaker/adoption/output_zone_sample/differences.csv\", Body=open(diff_file, \"rb\"))\n",
    "    print(f\" Differences saved to s3://{bucket}/sagemaker/adoption/output_zone_sample/differences.csv\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fc56492-b30c-4ef1-bc77-75274259d918",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lastly Comparing Performance\n",
    "import boto3\n",
    "import pandas as pd\n",
    "import io\n",
    "from sklearn.metrics import confusion_matrix, classification_report, ConfusionMatrixDisplay, roc_auc_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Config \n",
    "bucket = \"sagemaker-us-east-2-917456409349\"\n",
    "predicted_key = \"sagemaker/adoption/output_zone_sample/sample_data_output.csv\"\n",
    "golden_key = \"sagemaker/adoption/golden_record/df_cat_dog_harmonized_Sample_With_Outcome.csv\"\n",
    "\n",
    "s3 = boto3.client('s3')\n",
    "\n",
    "# Load function \n",
    "def load_csv(bucket, key):\n",
    "    obj = s3.get_object(Bucket=bucket, Key=key)\n",
    "    return pd.read_csv(io.BytesIO(obj['Body'].read()))\n",
    "\n",
    "# Load data \n",
    "print(\" Loading predicted and golden files...\")\n",
    "df_pred = load_csv(bucket, predicted_key)\n",
    "df_golden = load_csv(bucket, golden_key)\n",
    "\n",
    "print(f\" Predicted file: {df_pred.shape}\")\n",
    "print(f\" Golden file: {df_golden.shape}\")\n",
    "\n",
    "# Ensure primary_key exists \n",
    "if \"primary_key\" not in df_pred.columns or \"primary_key\" not in df_golden.columns:\n",
    "    raise ValueError(\" primary_key column missing in one of the files.\")\n",
    "\n",
    "# Prepare ground truth \n",
    "df_golden[\"actual_label\"] = df_golden[\"outcome_type_harmonized_grouped\"].apply(\n",
    "    lambda x: 1 if str(x).lower() == \"adopted\" else 0\n",
    ")\n",
    "\n",
    "# Join on primary_key \n",
    "df_joined = pd.merge(df_pred, df_golden[[\"primary_key\", \"actual_label\"]], on=\"primary_key\", how=\"inner\")\n",
    "print(f\" Joined data: {df_joined.shape}\")\n",
    "\n",
    "# Check required columns -\n",
    "if \"predicted_label\" not in df_joined.columns:\n",
    "    raise ValueError(\" predicted_label column not found in predicted file.\")\n",
    "if \"predicted_proba\" not in df_joined.columns:\n",
    "    raise ValueError(\" predicted_proba column missing. Add probabilities for AUC calculation.\")\n",
    "\n",
    "# Extract labels and probabilities \n",
    "y_true = df_joined[\"actual_label\"]\n",
    "y_pred = df_joined[\"predicted_label\"]\n",
    "y_proba = df_joined[\"predicted_proba\"]\n",
    "\n",
    "# Compute metrics \n",
    "print(\"\\n Classification Report:\")\n",
    "print(classification_report(y_true, y_pred, zero_division=0))\n",
    "\n",
    "# --- Compute AUC ---\n",
    "auc = roc_auc_score(y_true, y_proba)\n",
    "print(f\" ROC AUC Score: {auc:.4f}\")\n",
    "\n",
    "# --- Confusion Matrix ---\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=[\"Not Adopted\", \"Adopted\"])\n",
    "disp.plot(cmap=\"Blues\", values_format=\"d\")\n",
    "plt.title(f\"Confusion Matrix (AUC={auc:.3f})\")\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "929709de-db54-4df4-84bc-831e24517786",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4767735c-4723-4dd7-b73a-42e124294916",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Need to draw out prime features from XGBOOST or other model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed6fba08-e78c-4294-a5d6-de219b78f444",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Build Shap EXplainer .py\n",
    "#Built Lambda Function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36b211ae-d0f2-4aa1-aaca-5e69aad9faca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import tarfile\n",
    "\n",
    "bucket = 'sagemaker-us-east-2-917456409349'\n",
    "key = 'sagemaker/adoption/output/adoption-xgboost-2025-07-17-00-53-45/output/model.tar.gz'\n",
    "local_path = './model.tar.gz'  # Download into current directory\n",
    "\n",
    "# Download the model tar from S3\n",
    "s3 = boto3.client('s3')\n",
    "s3.download_file(bucket, key, local_path)\n",
    "\n",
    "# Extract locally\n",
    "with tarfile.open(local_path) as tar:\n",
    "    tar.extractall(path='./model')\n",
    "\n",
    "print(\"Model extracted to ./model directory\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f971980-e701-4e92-8e05-9fb034ed4163",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pulling Down Scored Sampel from S3\n",
    "!aws s3 cp s3://sagemaker-us-east-2-917456409349/sagemaker/adoption/output_zone_sample/sample_data_output.csv scored.csv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e7e32cd-6335-4805-9a1b-10b55f59ab39",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Testing Locally\n",
    "import tarfile\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "\n",
    "\n",
    "# Paths\n",
    "\n",
    "model_tar_path = 'model.tar.gz'  # Downloaded from S3\n",
    "input_csv_path = 'scored.csv'    # Downloaded from S3\n",
    "output_csv_path = 'final_with_shap.csv'\n",
    "\n",
    "\n",
    "# Full Feature List (22 columns)\n",
    "\n",
    "feature_cols = [\n",
    "    'Encoded-animal_type',\n",
    "    'Encoded-primary_breed_harmonized',\n",
    "    'Encoded-primary_color_harmonized',\n",
    "    'Encoded-sex',\n",
    "    'Encoded-intake_type_harmonized',\n",
    "    'Encoded-Is_returned',\n",
    "    'Encoded-has_name',\n",
    "    'Encoded-is_mix',\n",
    "    'age_months',\n",
    "    'Num_returned',\n",
    "    'stay_length_days',\n",
    "    'min_height',\n",
    "    'max_height',\n",
    "    'min_weight',\n",
    "    'max_weight',\n",
    "    'min_expectancy',\n",
    "    'max_expectancy',\n",
    "    'grooming_frequency_value',\n",
    "    'shedding_value',\n",
    "    'energy_level_value',\n",
    "    'trainability_value',\n",
    "    'demeanor_value'\n",
    "]\n",
    "\n",
    "\n",
    "# Extract Model\n",
    "\n",
    "with tarfile.open(model_tar_path) as tar:\n",
    "    tar.extractall(path='./model')\n",
    "model_file = './model/xgboost-model'\n",
    "\n",
    "\n",
    "# Load Model\n",
    "\n",
    "booster = xgb.Booster()\n",
    "booster.load_model(model_file)\n",
    "\n",
    "\n",
    "# Load Scored Data\n",
    "\n",
    "df = pd.read_csv(input_csv_path)\n",
    "print(f\"Loaded scored data with shape: {df.shape}\")\n",
    "\n",
    "# Ensure all required features exist\n",
    "missing = [col for col in feature_cols if col not in df.columns]\n",
    "if missing:\n",
    "    raise ValueError(f\"Missing required features in scored file: {missing}\")\n",
    "\n",
    "\n",
    "# Compute SHAP values\n",
    "\n",
    "dmatrix = xgb.DMatrix(df[feature_cols])\n",
    "shap_values = booster.predict(dmatrix, pred_contribs=True)\n",
    "\n",
    "# Create SHAP DataFrame\n",
    "shap_df = pd.DataFrame(shap_values, columns=feature_cols + ['bias']).drop(columns=['bias'])\n",
    "\n",
    "# Rename SHAP columns for clarity\n",
    "rename_map = {col: f\"SHAP-{col.replace('Encoded-', '').replace('_', ' ').title()}\" for col in feature_cols}\n",
    "shap_df.rename(columns=rename_map, inplace=True)\n",
    "\n",
    "# Append SHAP columns to original DataFrame\n",
    "df = pd.concat([df, shap_df], axis=1)\n",
    "\n",
    "\n",
    "# Compute Top Positive & Negative Features with SHAP values\n",
    "\n",
    "pos1, pos2, pos3, neg1, neg2, neg3 = [], [], [], [], [], []\n",
    "\n",
    "for i in range(shap_df.shape[0]):\n",
    "    row = shap_df.iloc[i]\n",
    "\n",
    "    # Sort positive and negative SHAP values\n",
    "    pos_sorted = row[row > 0].sort_values(ascending=False)\n",
    "    neg_sorted = row[row < 0].sort_values(ascending=True)  # ascending for negative (most negative first)\n",
    "\n",
    "    # Format as \"Feature (value)\"\n",
    "    p1 = f\"{pos_sorted.index[0]} ({pos_sorted.iloc[0]:.4f})\" if len(pos_sorted) > 0 else \"None\"\n",
    "    p2 = f\"{pos_sorted.index[1]} ({pos_sorted.iloc[1]:.4f})\" if len(pos_sorted) > 1 else \"None\"\n",
    "    p3 = f\"{pos_sorted.index[2]} ({pos_sorted.iloc[2]:.4f})\" if len(pos_sorted) > 2 else \"None\"\n",
    "\n",
    "    n1 = f\"{neg_sorted.index[0]} ({neg_sorted.iloc[0]:.4f})\" if len(neg_sorted) > 0 else \"None\"\n",
    "    n2 = f\"{neg_sorted.index[1]} ({neg_sorted.iloc[1]:.4f})\" if len(neg_sorted) > 1 else \"None\"\n",
    "    n3 = f\"{neg_sorted.index[2]} ({neg_sorted.iloc[2]:.4f})\" if len(neg_sorted) > 2 else \"None\"\n",
    "\n",
    "    pos1.append(p1)\n",
    "    pos2.append(p2)\n",
    "    pos3.append(p3)\n",
    "    neg1.append(n1)\n",
    "    neg2.append(n2)\n",
    "    neg3.append(n3)\n",
    "\n",
    "# Add to DataFrame\n",
    "df['Positive_Feature_1'] = pos1\n",
    "df['Positive_Feature_2'] = pos2\n",
    "df['Positive_Feature_3'] = pos3\n",
    "df['Negative_Feature_1'] = neg1\n",
    "df['Negative_Feature_2'] = neg2\n",
    "df['Negative_Feature_3'] = neg3\n",
    "\n",
    "\n",
    "#  Save Enriched File\n",
    "\n",
    "df.to_csv(output_csv_path, index=False)\n",
    "print(f\" SHAP file saved as: {output_csv_path}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a0d025e-4561-4c53-be57-c9ac88766203",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Showing performance\n",
    "import pandas as pd\n",
    "import boto3\n",
    "from io import BytesIO\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, f1_score, roc_auc_score,\n",
    "    roc_curve, confusion_matrix, ConfusionMatrixDisplay\n",
    ")\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load ground truth from S3\n",
    "bucket = \"sagemaker-us-east-2-917456409349\"\n",
    "key = \"sagemaker/adoption/golden_record/df_cat_dog_harmonized_Sample_With_Outcome.csv\"\n",
    "\n",
    "s3 = boto3.client('s3')\n",
    "obj = s3.get_object(Bucket=bucket, Key=key)\n",
    "df_true = pd.read_csv(BytesIO(obj['Body'].read()))\n",
    "\n",
    "# Convert ground truth to binary: adopted=1 else 0\n",
    "df_true['true_label'] = (df_true['outcome_type_harmonized_grouped'] == 'adopted').astype(int)\n",
    "\n",
    "# Load predicted local file\n",
    "df_pred = pd.read_csv(\"final_with_shap.csv\")\n",
    "\n",
    "# Merge on primary_key\n",
    "df_merged = pd.merge(df_true[['primary_key', 'true_label']], df_pred[['primary_key', 'predicted_label', 'predicted_proba']], on='primary_key')\n",
    "\n",
    "# Extract arrays\n",
    "y_true = df_merged['true_label']\n",
    "y_pred = df_merged['predicted_label']\n",
    "y_proba = df_merged['predicted_proba']\n",
    "\n",
    "# Calculate metrics\n",
    "accuracy = accuracy_score(y_true, y_pred)\n",
    "precision = precision_score(y_true, y_pred, zero_division=0)\n",
    "recall = recall_score(y_true, y_pred, zero_division=0)\n",
    "f1 = f1_score(y_true, y_pred, zero_division=0)\n",
    "auc = roc_auc_score(y_true, y_proba)\n",
    "\n",
    "print(f\" Scored file shape: {df_pred.shape}\")\n",
    "print(f\" Golden file shape: {df_true.shape}\")\n",
    "print(f\" Merged shape: {df_merged.shape}\\n\")\n",
    "\n",
    "print(\" PERFORMANCE METRICS\")\n",
    "print(f\" Accuracy:  {accuracy:.4f}\")\n",
    "print(f\" Precision: {precision:.4f}\")\n",
    "print(f\" Recall:    {recall:.4f}\")\n",
    "print(f\" F1 Score:  {f1:.4f}\")\n",
    "print(f\" AUC:       {auc:.4f}\")\n",
    "\n",
    "# Confusion matrix\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "disp.plot()\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.show()\n",
    "\n",
    "# ROC Curve\n",
    "fpr, tpr, thresholds = roc_curve(y_true, y_proba)\n",
    "plt.plot(fpr, tpr, label=f'AUC = {auc:.4f}')\n",
    "plt.plot([0, 1], [0, 1], linestyle='--', color='gray')\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.title(\"ROC Curve\")\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
